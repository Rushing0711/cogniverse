# ç¬¬5ç«  Kubernetesæ‰©å±•æœåŠ¡å®‰è£…

## 1 éƒ¨ç½²dashboardï¼ˆåœ¨masterèŠ‚ç‚¹æ‰§è¡Œï¼‰

[kuberneteså®˜æ–¹æä¾›çš„å¯è§†åŒ–ç•Œé¢](https://github.com/kubernetes/dashboard)

### 1.1 éƒ¨ç½²

ç‰ˆæœ¬å…¼å®¹æ€§ï¼šhttps://github.com/kubernetes/dashboard/releases 

å¯ä»¥å¾—çŸ¥dashboard v2.5.1 å…¼å®¹ kubernetes v1.23 ç‰ˆæœ¬

[dashboard v2.5.1æ–‡æ¡£](https://github.com/kubernetes/dashboard/tree/v2.5.1)

1. å®‰è£…

```bash
$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.5.1/aio/deploy/recommended.yaml
```

> è‹¥æ— æ³•ä¸‹è½½æ–‡ä»¶ï¼Œå…ˆæ‰§è¡Œä¸‹è½½ `curl https://raw.githubusercontent.com/kubernetes/dashboard/v2.5.1/aio/deploy/recommended.yaml -O` å†æ‰§è¡Œ `kubectl apply -f recommended.yaml`

2. è®¾ç½®è®¿é—®ç«¯å£

  - æ–¹å¼ä¸€ï¼šæ‰‹å·¥ç¼–è¾‘

  ```bash
$ kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard
  ```

  æ˜¾ç¤ºå˜æ›´çš„éƒ¨åˆ†ï¼š

  ```js
spec:
  clusterIP: 10.96.11.88
  clusterIPs:
  - 10.96.11.88
  internalTrafficPolicy: Cluster
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
  ports:
  - port: 443
    protocol: TCP
    targetPort: 8443
  selector:
    k8s-app: kubernetes-dashboard
  sessionAffinity: None
  type: ClusterIP // [!code --] [!code focus:2]
  type: NodePort // [!code ++]
status:
  loadBalancer: {}
  ```

  è®¿é—®åœ°å€ï¼š`kubectl get svc -n kubernetes-dashboard` æŸ¥çœ‹æš´éœ²çš„éšæœºç«¯å£ã€‚

  > ç¤ºä¾‹ï¼š
  >
  > ```bash
  > $ kubectl get svc -n kubernetes-dashboard
  > NAME                        TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)         AGE
  > dashboard-metrics-scraper   ClusterIP   10.96.40.11   <none>        8000/TCP        19m
  > kubernetes-dashboard        NodePort    10.96.11.88   <none>        443:30443/TCP   19m
  > ```
  >
  > å¯ä»¥çœ‹åˆ°ç«¯å£ 30443

  - æ–¹å¼äºŒï¼šå‘½ä»¤è°ƒæ•´

  ```bash
$ kubectl patch svc kubernetes-dashboard -n kubernetes-dashboard \
  -p '{"spec": {"type": "NodePort", "ports": [{"port": 443, "nodePort": 30443}]}}'
  ```

  è®¿é—®åœ°å€ï¼š
  https://<èŠ‚ç‚¹IP>:30443

---



<span style="color:red;font-weight:bold;">chromeä¸è®©è®¿é—®æ— æ•ˆè¯ä¹¦çš„httpsç½‘ç«™ï¼Œå¦‚ä½•å¤„ç†ï¼Ÿ</span>

âš ï¸ æ–¹æ³•ä¸€ï¼šç›´æ¥è¾“å…¥å¿½ç•¥å‘½ä»¤ï¼ˆæœ€ç®€å•å¿«é€Ÿï¼‰

å½“çœ‹åˆ° **`æ‚¨çš„è¿æ¥ä¸æ˜¯ç§å¯†è¿æ¥`** æˆ– **`NET::ERR_CERT_INVALID`** é”™è¯¯é¡µé¢æ—¶ï¼š

1. **å°†å…‰æ ‡ç‚¹å‡»åˆ°é”™è¯¯é¡µé¢ç©ºç™½å¤„**ï¼ˆç¡®ä¿åœ°å€æ æœªæ¿€æ´»ï¼‰ã€‚

2. **ç›´æ¥è¾“å…¥**ï¼ˆæ— éœ€ç²˜è´´ï¼‰ä»¥ä¸‹è‹±æ–‡å•è¯ï¼š

   ```
   thisisunsafe
   ```

3. é¡µé¢ä¼šè‡ªåŠ¨åˆ·æ–°å¹¶å…è®¸è®¿é—®ã€‚

> âœ… **ä¼˜ç‚¹**ï¼šæ— éœ€é‡å¯æµè§ˆå™¨æˆ–ä¿®æ”¹é…ç½®ã€‚
> âŒ **ç¼ºç‚¹**ï¼šæ¯æ¬¡è®¿é—®æ–°ç«¯å£æˆ–é‡å¯æœåŠ¡åéœ€é‡æ–°è¾“å…¥ã€‚



---



è®¿é—®é€šè¿‡åï¼Œå¯ä»¥çœ‹åˆ°å¦‚ä¸‹ç•Œé¢ï¼š

![image-20250602194303119](images/image-20250602194303119.png)

---

3. åˆ›å»ºè®¿é—®è´¦å·

[åˆ›å»ºè®¿é—®è´¦å·](https://github.com/kubernetes/dashboard/blob/v2.5.1/docs/user/access-control/creating-sample-user.md)

```bash
$ tee dashboard-adminuser.yaml <<EOF
# æˆ‘ä»¬é¦–å…ˆåœ¨å‘½åç©ºé—´ kubernetes-dashboard ä¸­åˆ›å»ºåä¸º admin-user çš„æœåŠ¡è´¦æˆ·ã€‚
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kubernetes-dashboard
---
# åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œä½¿ç”¨ kops ã€ kubeadm æˆ–å…¶ä»–æµè¡Œå·¥å…·é…ç½®é›†ç¾¤åï¼Œ ClusterRole cluster-admin åœ¨é›†ç¾¤ä¸­å·²ç»å­˜åœ¨ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å®ƒï¼Œå¹¶ä»…ä¸ºæˆ‘ä»¬çš„ ServiceAccount åˆ›å»ºä¸€ä¸ª ClusterRoleBinding ã€‚å¦‚æœä¸å­˜åœ¨ï¼Œåˆ™éœ€è¦é¦–å…ˆåˆ›å»ºæ­¤è§’è‰²ï¼Œå¹¶æ‰‹åŠ¨æˆäºˆæ‰€éœ€æƒé™ã€‚
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: admin-user
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kubernetes-dashboard
EOF
```

```bash
$ kubectl apply -f dashboard-adminuser.yaml
```

4. è·å– Bearer ä»¤ç‰Œ

```bash
$ kubectl -n kubernetes-dashboard get secret $(kubectl -n kubernetes-dashboard get sa/admin-user -o jsonpath="{.secrets[0].name}") -o go-template="{{.data.token | base64decode}}"
```

å®ƒåº”è¯¥ä¼šæ‰“å°å‡ºç±»ä¼¼ä»¥ä¸‹å†…å®¹ï¼š

```bash
eyJhbGciOiJSUzI1NiIsImtpZCI6InAxYVVVQWpYTFBZbzVianl5c1VKOUt1MGFtT25GNjFxTDlMOV9md09sYlkifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLWp2MnRrIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiI2YmFjZTU0YS0zNTliLTRhNjYtOTFiMi04MWEyODMzZDI1MDciLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.T1UTl_dlX1zW09VAI3lGIYmqQI3b3Sy194KKO2HxcR7zUuf_8P8HrXivcvva3U8r7BdrKmo4aSoh-12CdjY6tui5jvg_Wmp9n212AZOhI47mQzDW4IiDRU-37Iv6yg-FRc4OnGJipYOnoAWHUxSwiVAhiCtL9PgZ9vIIde0z8EcwTWGJ896S6ugN0wBrPJHwCH3IkPRVwloPkLX9A1UQnEiSZOTHzJvvr_cAc3D95XjBT9NIvmjgHXcve74LnEE_SngJ-b-9fyqxYdzyknrGmnwNrhwle30rlr9lBSby_4x51_a7V7fK8EzgIoafNYcdIVWSE1iLtA4x-Qw-NBTvNQ
```

ç°åœ¨å¤åˆ¶è¯¥ä»¤ç‰Œï¼Œå¹¶å°†å…¶ç²˜è´´åˆ°ç™»å½•ç•Œé¢çš„ `Enter token` å­—æ®µä¸­ã€‚

![image-20250602200215542](images/image-20250602200215542.png)

ç‚¹å‡» `Sign in` æŒ‰é’®ï¼Œæå®šã€‚ä½ ç°åœ¨å·²ä»¥ç®¡ç†å‘˜èº«ä»½ç™»å½•ã€‚

5. ç•Œé¢

![image-20250602200414223](images/image-20250602200414223.png)

### 1.2 å¸è½½

- åˆ é™¤ç®¡ç†å‘˜ `ServiceAccount` å’Œ `ClusterRoleBinding` 

```bash
$ kubectl -n kubernetes-dashboard delete serviceaccount admin-user
$ kubectl -n kubernetes-dashboard delete clusterrolebinding admin-user
```

- å¸è½½dashboardç»„ä»¶

```bash
$ kubectl delete -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.5.1/aio/deploy/recommended.yaml
```

### 1.3 åŒç±»å‹è½¯ä»¶æ ¸å¿ƒå¯¹æ¯”è¡¨

| **ç‰¹æ€§**          | **Kubernetes Dashboard** | **KubeSphere**                            | **Rancher**                     |
| :---------------- | :----------------------- | :---------------------------------------- | :------------------------------ |
| **é¡¹ç›®èƒŒæ™¯**      | Kubernetes å®˜æ–¹é¡¹ç›®      | é’äº‘å¼€æº (CNCF é¡¹ç›®)                      | Rancher Labs (ç°å± SUSE)        |
| **å®šä½**          | å•é›†ç¾¤ Web UI            | **å…¨æ ˆå®¹å™¨å¹³å°**                          | **ä¼ä¸šçº§å¤šé›†ç¾¤ç®¡ç†**            |
| **å¤šé›†ç¾¤ç®¡ç†**    | âŒ ä»…å•é›†ç¾¤               | âœ… æ”¯æŒ                                    | âœ… **æ ¸å¿ƒä¼˜åŠ¿** (æ··åˆäº‘/å¤šäº‘)    |
| **éƒ¨ç½²å¤æ‚åº¦**    | â­ ç®€å• (`kubectl apply`) | â­â­â­ ä¸­ç­‰ (éœ€è§„åˆ’å­˜å‚¨/ç½‘ç»œ)                | â­â­ ä¸­ç­‰ (Helm éƒ¨ç½²)             |
| **åº”ç”¨å•†åº—**      | âŒ æ—                      | âœ… **å†…ç½®** (300+ Helm Charts)             | âœ… **å†…ç½®** (æ”¯æŒè‡ªå®šä¹‰ Catalog) |
| **DevOps æµæ°´çº¿** | âŒ æ—                      | âœ… **å®Œæ•´é›†æˆ** (Jenkins/SonarQube/GitOps) | âœ… æ”¯æŒ (éœ€é›†æˆå¤–éƒ¨å·¥å…·)         |
| **ç›‘æ§å‘Šè­¦**      | âŒ åŸºç¡€æŒ‡æ ‡               | âœ… **å¼€ç®±å³ç”¨** (Prometheus+Grafana+å‘Šè­¦)  | âœ… é›†æˆ (éœ€é¢å¤–é…ç½®)             |
| **æ—¥å¿—ç®¡ç†**      | âŒ ä»… Pod æ—¥å¿—            | âœ… **ELK/Fluentd é›†æˆ**                    | âŒ éœ€è‡ªè¡Œæ­å»º                    |
| **æœåŠ¡ç½‘æ ¼**      | âŒ æ—                      | âœ… **å†…ç½® Istio**                          | âŒ éœ€æ‰‹åŠ¨é›†æˆ                    |
| **å¤šç§Ÿæˆ·éš”ç¦»**    | â­ RBAC åŸºç¡€æ§åˆ¶          | âœ… **ä¼ä¸šçº§ç§Ÿæˆ·ä½“ç³»**                      | âœ… **ç»†ç²’åº¦ RBAC+é¡¹ç›®éš”ç¦»**      |
| **è¾¹ç¼˜è®¡ç®—æ”¯æŒ**  | âŒ æ—                      | âœ… **KubeEdge é›†æˆ**                       | âœ… **K3s è½»é‡é›†ç¾¤**              |
| **UI ä½“éªŒ**       | â­ åŠŸèƒ½å¯¼å‘ (ç®€æ´)        | â­â­â­ **ç°ä»£åŒ–æ§åˆ¶å°** (å¤šæ¨¡å—é›†æˆ)         | â­â­ åŠŸèƒ½ä¸°å¯Œ (å­¦ä¹ æ›²çº¿ç¨é™¡)      |
| **æœ€ä½³é€‚ç”¨åœºæ™¯**  | å¼€å‘è°ƒè¯•/å•é›†ç¾¤è¿ç»´      | **ä¼ä¸šçº§å…¨æ ˆå¹³å°** (DevOps+å¾®æœåŠ¡+ç›‘æ§)   | **æ··åˆäº‘/å¤§è§„æ¨¡é›†ç¾¤èˆ°é˜Ÿç®¡ç†**   |

**æ€»ç»“å»ºè®®**

- **é€‰ Kubernetes Dashboard å¦‚æœ**ï¼š
  éœ€è¦è½»é‡çº§ K8s æ“ä½œç•Œé¢ï¼Œä¸”ä»…ç®¡ç†å•ä¸ªé›†ç¾¤ã€‚
- **é€‰ KubeSphere å¦‚æœ**ï¼š
  æ„å»º **ä¸€ä½“åŒ–ä¼ä¸šå¹³å°**ï¼ˆå°¤å…¶éœ€è¦å¼€ç®±å³ç”¨çš„ DevOps/å¾®æœåŠ¡/ç›‘æ§ï¼‰ã€‚
- **é€‰ Rancher å¦‚æœ**ï¼š
  ç®¡ç† **è·¨äº‘/æ··åˆäº‘é›†ç¾¤èˆ°é˜Ÿ** æˆ–ä¸“æ³¨ **é›†ç¾¤ç”Ÿå‘½å‘¨æœŸç®¡ç†**ã€‚

> ğŸ’¡ **ç»„åˆç­–ç•¥**ï¼šå¤§å‹ä¼ä¸šå¯åŒæ—¶ä½¿ç”¨ Rancherï¼ˆå¤šé›†ç¾¤æ²»ç†ï¼‰ + KubeSphereï¼ˆé›†ç¾¤å†…åº”ç”¨å¹³å°ï¼‰ï¼Œé€šè¿‡ Rancher çº³ç®¡éƒ¨ç½²äº† KubeSphere çš„é›†ç¾¤ã€‚

## 2 å®‰è£…ingress-nginxï¼ˆåœ¨masterèŠ‚ç‚¹æ‰§è¡Œï¼‰

[ingress-nginx GitHubæŸ¥çœ‹ä¸K8Sç‰ˆæœ¬å…¼å®¹æ€§](https://github.com/kubernetes/ingress-nginx)

ingress-nginxå®˜ç½‘éƒ¨ç½²ï¼šhttps://kubernetes.github.io/ingress-nginx/deploy/

ingress-nginxå®˜ç½‘ç”¨æˆ·æŒ‡å—ï¼šhttps://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/

### 2.1 åˆ‡æ¢ç›®å½•

```bash
$ cd
$ mkdir -pv /root/k8s_soft/k8s_v1.23.17 && cd /root/k8s_soft/k8s_v1.23.17
```

### 2.2 ä¸‹è½½æ–‡ä»¶ä¸é…ç½®è°ƒæ•´

```bash
# ä¸‹è½½ https://github.com/kubernetes/ingress-nginx/blob/controller-v1.6.4/deploy/static/provider/cloud/deploy.yaml åˆ° ingress-nginx.yaml
# è‹¥ raw.githubusercontent.com æ— æ³•è®¿é—®ï¼Œå¯ä»¥é€šè¿‡ https://www.ipaddress.com æŸ¥è¯¢å…¶ipåœ°å€å¹¶é…ç½®æœ¬åœ°dns
$ curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.6.4/deploy/static/provider/cloud/deploy.yaml -o ingress-nginx.yaml
```

#### 2.2.1 è°ƒæ•´é•œåƒ

è‹¥ä¸è°ƒæ•´ï¼Œä¸‹è½½åå¯èƒ½æ˜¯è¿™æ ·çš„é•œåƒï¼š

```bash
registry.k8s.io/ingress-nginx/controller   <none>     81a20af4ae3c   2 years ago   282MB
registry.k8s.io/ingress-nginx/kube-webhook-certgen   <none>     7650062bc6ee   2 years ago     44.9MB
```

- è°ƒæ•´é•œåƒåç§°

```bash
$ sed -i.bak 's/image: registry.k8s.io\/ingress-nginx\/controller:v1.6.3@sha256:b92667e0afde1103b736e6a3f00dd75ae66eec4e71827d19f19f471699e909d2/image: registry.k8s.io\/ingress-nginx\/controller:v1.6.3/g;s/image: registry.k8s.io\/ingress-nginx\/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f/image: registry.k8s.io\/ingress-nginx\/kube-webhook-certgen:v20220916-gd32f8c343/g' ingress-nginx.yaml
```

> è¯´æ˜ï¼šæºæ–‡ä»¶å¤‡ä»½åˆ° ingress-nginx.yaml.bak

#### 2.2.2 è°ƒæ•´Service

- è°ƒæ•´Serviceçš„typeä¸º NodePort å¹¶å›ºå®š nodePort ä¸º80å’Œ443

æ˜¾ç¤ºå˜æ›´çš„éƒ¨åˆ†ï¼š

```js
apiVersion: v1
kind: Service
metadata: 
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.6.3
  name: ingress-nginx-controller
  namespace: ingress-nginx
spec:
  externalTrafficPolicy: Local
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
  ports:
  - appProtocol: http
    name: http
    port: 80
    protocol: TCP
    targetPort: http
    nodePort: 80 // [!code ++] [!code focus]
  - appProtocol: https
    name: https
    port: 443
    protocol: TCP
    targetPort: https
    nodePort: 443 // [!code ++] [!code focus]
  selector:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
  type: LoadBalancer // [!code --] [!code focus:2]
  type: NodePort // [!code ++]
```

- è°ƒæ•´nodePortå…è®¸çš„ç«¯å£èŒƒå›´ï¼ˆåœ¨masterèŠ‚ç‚¹ï¼‰

ä¸Šé¢ç›´æ¥è®¾ç½®ä¸º80å’Œ443ä¼šæŠ¥é”™ï¼šnodePort: Invalid value valid ports is 30000-32767

> ä½¿ç”¨`kubectl apply`å®‰è£…æ—¶æŠ¥é”™ï¼š
>
> <span style="color:red;font-weight:bold;">The Service "ingress-nginx-controller" is invalid: spec.ports[0].nodePort: Invalid value: 80: provided port is not in the valid range. The range of valid ports is 30000-32767</span>

æ˜¯å› ä¸ºk8sçš„nodeèŠ‚ç‚¹çš„ç«¯å£é»˜è®¤è¢«é™åˆ¶åœ¨30000-32767çš„èŒƒå›´ã€‚

ä¿®æ”¹nodeèŠ‚ç‚¹çš„å…è®¸èŒƒå›´ï¼š

```bash
$ vim /etc/kubernetes/manifests/kube-apiserver.yaml 
```

åœ¨ spec.containers.command ä¸­æ‰¾åˆ°`- --service-cluster-ip-range`ï¼Œå¹¶åœ¨å…¶åå¢åŠ ä¸€è¡Œï¼š

```bash
    - --service-node-port-range=1-65535
```

- é‡å¯

```bash
$ systemctl daemon-reload && systemctl restart kubelet
```

#### 2.2.3 è°ƒæ•´Deployment

ä¿®æ”¹kindæ¨¡å¼ Deployment ==> DaemonSet

```js
apiVersion: apps/v1
kind: Deployment // [!code --] [!code focus:2]
kind: DaemonSet // [!code ++]
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.6.3
  name: ingress-nginx-controller
```

### 2.3 å®‰è£…ingress-nginx

- å®‰è£…æ’ä»¶ï¼ˆmasterèŠ‚ç‚¹ï¼‰

```bash
# é…ç½®èµ„æº
$ kubectl apply -f ingress-nginx.yaml
# æŸ¥çœ‹
$ kubectl get all -n ingress-nginx -o wide
NAME                                       READY   STATUS      RESTARTS   AGE   IP               NODE    NOMINATED NODE   READINESS GATES
pod/ingress-nginx-admission-create-b7mrj   0/1     Completed   0          70s   10.244.161.5     emon3   <none>           <none>
pod/ingress-nginx-admission-patch-rcgvw    0/1     Completed   0          70s   10.244.108.111   emon2   <none>           <none>
pod/ingress-nginx-controller-52dd7         1/1     Running     0          70s   10.244.161.7     emon3   <none>           <none>
pod/ingress-nginx-controller-n4mwx         1/1     Running     0          70s   10.244.108.112   emon2   <none>           <none>

NAME                                         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                 AGE   SELECTOR
service/ingress-nginx-controller             NodePort    10.96.217.34   <none>        80:80/TCP,443:443/TCP   71s   app.kubernetes.io/component=controller,app.kubernetes.io/instance=ingress-nginx,app.kubernetes.io/name=ingress-nginx
service/ingress-nginx-controller-admission   ClusterIP   10.96.60.43    <none>        443/TCP                 71s   app.kubernetes.io/component=controller,app.kubernetes.io/instance=ingress-nginx,app.kubernetes.io/name=ingress-nginx

NAME                                      DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE   CONTAINERS   IMAGES                                            SELECTOR
daemonset.apps/ingress-nginx-controller   2         2         2       2            2           kubernetes.io/os=linux   71s   controller   registry.k8s.io/ingress-nginx/controller:v1.6.3   app.kubernetes.io/component=controller,app.kubernetes.io/instance=ingress-nginx,app.kubernetes.io/name=ingress-nginx

NAME                                       COMPLETIONS   DURATION   AGE   CONTAINERS   IMAGES                                                                    SELECTOR
job.batch/ingress-nginx-admission-create   1/1           4s         71s   create       registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343   controller-uid=59ba2850-e57d-4ed5-9968-c37aefd14a32
job.batch/ingress-nginx-admission-patch    1/1           2s         70s   patch        registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343   controller-uid=144e3f71-16fe-4837-bf3a-e17a759e655e
```

### 2.4 æµ‹è¯•æœåŠ¡

#### 2.5.1 ingress-test.yamlé…ç½®

:::details ingress-test.yamlé…ç½®

```bash
$ tee ingress-test.yaml << EOF
#deploy
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
spec:
  selector:
    matchLabels:
      app: nginx-pod
  replicas: 1
  template:
    metadata:
      labels:
        app: nginx-pod
    spec:
      containers:
      - name: nginx
        image: nginx:1.25.4
        ports:
        - containerPort: 80

---      
#deploy
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tomcat-deploy
spec:
  selector:
    matchLabels:
      app: tomcat-pod
  replicas: 1
  template:
    metadata:
      labels:
        app: tomcat-pod
    spec:
      containers:
      - name: tomcat
        image: tomcat:8.5-jre8-slim
        ports:
        - containerPort: 8080
        
---
#service
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx-pod
  type: ClusterIP
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80

---
#service
apiVersion: v1
kind: Service
metadata:
  name: tomcat-service
spec:
  selector:
    app: tomcat-pod
  type: ClusterIP
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080

---
#ingress
#old version: extensions/v1beta1
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-http
spec:
  ingressClassName: nginx
  rules:
  - host: nginx.fsmall.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: nginx-service
            port:
              number: 80
  - host: tomcat.fsmall.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: tomcat-service
            port:
              number: 80
EOF
```

:::

é…ç½®èµ„æºç”Ÿæ•ˆï¼š

:::code-group

```bash [åˆ›å»º]
$ kubectl apply -f ingress-test.yaml
```

```bash [åœ¨é›†ç¾¤å†…é€šè¿‡ç›®æ ‡scvè®¿é—®]
# æŸ¥çœ‹service
$ kubectl get svc
NAME             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
kubernetes       ClusterIP   10.96.0.1       <none>        443/TCP   5d
nginx-service    ClusterIP   10.96.236.244   <none>        80/TCP    9m43s
tomcat-service   ClusterIP   10.96.8.65      <none>        80/TCP    9m43s

# å‘½ä»¤è¡Œè®¿é—®service
$ curl 10.96.236.244:80
$ curl 10.96.8.65:80
```

```bash [åœ¨é›†ç¾¤å†…é€šè¿‡ingçš„svcè®¿é—®]
# æŸ¥çœ‹ingressçš„NodePortåœ°å€
$ kubectl get svc -n ingress-nginx
NAME                                 TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                 AGE
ingress-nginx-controller             NodePort    10.96.217.34   <none>        80:80/TCP,443:443/TCP   15m
ingress-nginx-controller-admission   ClusterIP   10.96.60.43    <none>        443/TCP                 15m
# å‘½ä»¤è¡Œè®¿é—®service
$ curl  -H "Host: nginx.fsmall.com" 10.96.217.34:80
$ curl  -H "Host: tomcat.fsmall.com" 10.96.217.34:80
```

```bash [åœ¨é›†ç¾¤å¤–é€šè¿‡ingåŸŸåè®¿é—®]
$ kubectl get ing
NAME           CLASS   HOSTS                                ADDRESS        PORTS   AGE
ingress-http   nginx   nginx.fsmall.com,tomcat.fsmall.com   10.96.217.34   80      11m

# é…ç½®æœ¬åœ°DNSï¼šè®¿é—®emon2æˆ–emon3çš„DNS
$ vim /etc/hosts
192.168.200.117 nginx.fsmall.com
192.168.200.118 tomcat.fsmall.com
192.168.200.117 api.fsmall.com

# è®¿é—®
http://nginx.fsmall.com # çœ‹åˆ°æ­£å¸¸nginxç•Œé¢
http://tomcat.fsmall.com # çœ‹åˆ°æ­£å¸¸tomcatç•Œé¢
http://api.fsmall.com # çœ‹åˆ° nginx çš„ 404 é¡µé¢
```

```bash [åˆ é™¤]
$ kubectl delete -f ingress-test.yaml
```

:::

### 2.5 å…¶ä»–

- ingressæœåŠ¡å®‰è£…åï¼Œç¡®ä¿é›†ç¾¤ä¸­å­˜åœ¨åä¸º `nginx` çš„ IngressClassï¼š

```bash
$ kubectl get ingressclass -n ingress-nginx
```

- è‹¥`kind: Ingress`åˆ›å»ºåï¼ŒæŸ¥çœ‹`<ingress-pod-name>`æ˜¯å¦ç”Ÿæˆè§„åˆ™

```bash
# æŸ¥çœ‹ingress-pod-nameï¼Œç¡®è®¤ Nginx Ingress Controller å·²å®‰è£…ä¸” Pod æ­£å¸¸è¿è¡Œï¼š
$ kubectl get po -n ingress-nginx|grep ingress-nginx-controller
# æŸ¥çœ‹ç”Ÿæˆçš„Nginxé…ç½®
$ kubectl exec -n ingress-nginx -it <ingress-pod-name> -- cat /etc/nginx/nginx.conf
```

- è‹¥å¹¶æ²¡æœ‰ç”Ÿæˆè§„åˆ™ï¼Œæ£€æŸ¥ Ingress Controller æ—¥å¿—æ˜¯å¦æœ‰é”™è¯¯ï¼š

```bash
$ kubectl logs -n ingress-nginx <ingress-pod-name>
```



## 3 é›†ç¾¤å†’çƒŸæµ‹è¯•ï¼ˆåœ¨masterèŠ‚ç‚¹æ‰§è¡Œï¼‰

### 3.1 åˆ›å»ºnginx-ds

:::details nginx-ds.yamlé…ç½®

```bash
$ tee nginx-ds.yaml << EOF
apiVersion: v1
kind: Service
metadata:
  name: nginx-ds
  labels:
    app: nginx-ds
spec:
  type: NodePort
  selector:
    app: nginx-ds
  ports:
  - name: http
    port: 80
    targetPort: 80
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nginx-ds
spec:
  selector:
    matchLabels:
      app: nginx-ds
  template:
    metadata:
      labels:
        app: nginx-ds
    spec:
      containers:
      - name: my-nginx
        image: nginx:1.25.4
        ports:
        - containerPort: 80
EOF
```

:::

- åˆ›å»º

```bash
$ kubectl apply -f nginx-ds.yaml
```

### 3.2 æ£€æŸ¥å„ç§ipè¿é€šæ€§

```bash
# æ£€æŸ¥å„ Node ä¸Šçš„ Pod IP è¿é€šæ€§
$ kubectl get pods -o wide

# åœ¨æ¯ä¸ªworkerèŠ‚ç‚¹ä¸Šping pod ip
# ä¸»èŠ‚ç‚¹ï¼š kubectl get pods -o wide|grep nginx-ds|awk '{print $6}'| xargs -I {} ping -c 1 "{}"
$ ping <pod-ip>

# æ£€æŸ¥serviceå¯è¾¾æ€§
$ kubectl get svc

# åœ¨æ¯ä¸ªworkerèŠ‚ç‚¹ä¸Šè®¿é—®æœåŠ¡ï¼Œè¿™é‡Œçš„<port>è¡¨ç¤ºé›†ç¾¤å†…ï¼ˆéNodePortç«¯å£ï¼‰
$ curl <service-ip>:<port>

# åœ¨æ¯ä¸ªèŠ‚ç‚¹æ£€æŸ¥node-portå¯ç”¨æ€§
$ curl <node-ip>:<port>
```

### 3.3 æ£€æŸ¥dnså¯ç”¨æ€§

:::code-group

```bash [é…ç½®]
$ cat > nginx-pod.yaml <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: docker.io/library/nginx:1.25.4
    ports:
    - containerPort: 80
EOF
```

```bash [åˆ›å»º]
$ kubectl apply -f nginx-pod.yaml
```

```bash [è¿›å…¥podæŸ¥çœ‹dns]
$ kubectl exec nginx -it -- cat /etc/resolv.conf
```

```bash [éªŒè¯è§£æ]
$ kubectl exec nginx -it -- curl nginx-ds
```

```bash [åˆ é™¤]
$ kubectl delete -f nginx-pod.yaml
```

:::

### 3.4 æ—¥å¿—åŠŸèƒ½

æµ‹è¯•ä½¿ç”¨kubectlæŸ¥çœ‹podçš„å®¹å™¨æ—¥å¿—

```bash
$ kubectl get pods
# å‘½ä»¤è¡Œè¾“å‡ºç»“æœ
NAME             READY   STATUS    RESTARTS   AGE
nginx            1/1     Running   0          54s
nginx-ds-dkfjm   1/1     Running   0          2m54s
nginx-ds-rx6mj   1/1     Running   0          2m54s

# æŸ¥çœ‹æ—¥å¿—
$ kubectl logs <pod-name>
```

### 3.5 ExecåŠŸèƒ½

æµ‹è¯•kubectlçš„execåŠŸèƒ½

```bash
# æŸ¥è¯¢æŒ‡å®šæ ‡ç­¾çš„pod
$ kubectl get pods -l app=nginx-ds
$ kubectl exec -it <nginx-pod-name> -- nginx -v
```

### 3.6 åˆ é™¤nginx-ds

```bash
$ kubectl delete -f nginx-ds.yaml
```

## 4 å­˜å‚¨æ–¹æ¡ˆ

<span style="color:red;font-weight:bold;">åœ¨dockerä¸­ï¼Œä»¥å‰æ˜¯å°†dockerå†…éƒ¨ç›®å½•æŒ‚è½½åˆ°æœºå™¨ä¸Šï¼Œä½†æ˜¯åœ¨k8sä¸­å¦‚æœå°†ç›®å½•æŒ‚è½½åˆ°æœºå™¨ä¸Šï¼Œå¦‚æœæŸä¸ªèŠ‚ç‚¹çš„å®¹å™¨æŒ‚äº†ï¼Œæ¯”å¦‚MySQLï¼Œk8sçš„è‡ªæ„ˆæœºåˆ¶ä¼šåœ¨å…¶å®ƒèŠ‚ç‚¹å†æ‹‰èµ·ä¸€ä»½ï¼Œé‚£å°±ä¼šå¯¼è‡´åŸæ¥çš„æ•°æ®ä¸¢å¤±äº†ï¼Œæ‰€ä»¥åœ¨k8sä¸­éœ€è¦åº”ç”¨åˆ°å­˜å‚¨å±‚ï¼šæ¯”å¦‚NFSã€OpenEBSï¼Œk8sä¼šå°†è¿™äº›å®¹å™¨çš„æ•°æ®å…¨éƒ¨å­˜åœ¨å­˜å‚¨å±‚ï¼Œè€Œè¿™ä¸ªå­˜å‚¨å±‚ä¼šåœ¨æ‰€æœ‰èŠ‚ç‚¹éƒ½æœ‰ä¸€ä»½ã€‚</span>

ä¸ºäº†æ‰©å±• K8s é›†ç¾¤çš„å­˜å‚¨èƒ½åŠ›ï¼Œæˆ‘ä»¬å°†å¿«é€Ÿå¯¹æ¥ NFS ä½œä¸º OpenEBS ä¹‹å¤–çš„å¦ä¸€ç§æŒä¹…åŒ–å­˜å‚¨ã€‚

æœ¬æ–‡åªä»‹ç» K8s é›†ç¾¤ä¸Šçš„æ“ä½œï¼ŒNFS æœåŠ¡å™¨çš„éƒ¨ç½²å’Œæ›´å¤šç»†èŠ‚è¯·å‚é˜…[æ¢ç´¢ Kubernetes æŒä¹…åŒ–å­˜å‚¨ä¹‹ NFS ç»ˆæå®æˆ˜æŒ‡å—](https://mp.weixin.qq.com/s/FRZppup6W_AS2O-_CR1KFg) ã€‚

### 4.0 K8S è®¿é—®æ¨¡å¼ï¼ˆAccess Modesï¼‰

| æ¨¡å¼ | å…¨ç§°          | å«ä¹‰       | å…¸å‹ç”¨é€”                                  |
| ---- | ------------- | ---------- | ----------------------------------------- |
| RWO  | ReadWriteOnce | å•èŠ‚ç‚¹è¯»å†™ | æ•°æ®åº“ï¼ˆMySQLã€PostgreSQLï¼‰ã€Redis ä¸»èŠ‚ç‚¹ |
| ROX  | ReadOnlyMany  | å¤šèŠ‚ç‚¹åªè¯» | é…ç½®æ–‡ä»¶ã€é™æ€èµ„æºã€æ¨¡æ¿                  |
| RWX  | ReadWriteMany | å¤šèŠ‚ç‚¹è¯»å†™ | Jenkins æ„å»ºç¼“å­˜ã€CMS ä¸Šä¼ ç›®å½•ã€æ—¥å¿—èšåˆ  |

> âš ï¸ æ³¨æ„ï¼š**â€œèŠ‚ç‚¹â€ â‰  â€œPodâ€**ã€‚RWO å…è®¸åŒä¸€èŠ‚ç‚¹ä¸Šçš„å¤šä¸ª Pod å…±äº«å·ï¼Œä½†ä¸èƒ½è·¨èŠ‚ç‚¹ã€‚



### 4.1 éƒ¨ç½²NFS

#### 4.1.0 NFS å­˜å‚¨æ–¹æ¡ˆ

 **âœ… åŠŸèƒ½ç‰¹ç‚¹**

- åŸºäº **ç½‘ç»œæ–‡ä»¶ç³»ç»Ÿåè®®**ï¼ˆPOSIX å…¼å®¹ï¼‰
- æ”¯æŒ **RWX**ï¼ˆå¤šèŠ‚ç‚¹å¹¶å‘è¯»å†™ï¼‰
- ç”± **å¤–éƒ¨ NFS Server** æä¾›æœåŠ¡ï¼ˆéœ€ç‹¬ç«‹éƒ¨ç½²ç»´æŠ¤ï¼‰
- æ— å†…ç½®å¿«ç…§ã€å¤åˆ¶ã€åŠ å¯†ç­‰ä¼ä¸šçº§åŠŸèƒ½ï¼ˆä¾èµ–åº•å±‚å®ç°ï¼‰

**ğŸ“Œ é€‚ç”¨åœºæ™¯**

- **å†…å®¹ç®¡ç†ç³»ç»Ÿ**ï¼ˆå¦‚ WordPress å¤šå®ä¾‹å…±äº« uploadsï¼‰
- **DevOps å·¥å…·é“¾**ï¼ˆJenkinsã€GitLab Runner å…±äº« workspaceï¼‰
- **åª’ä½“å¤„ç†æµæ°´çº¿**ï¼ˆå…¬å…±ç´ æåº“ï¼‰
- **å¼€å‘æµ‹è¯•ç¯å¢ƒ** çš„ä½æˆæœ¬å…±äº«å­˜å‚¨

**ğŸ”§ è®¿é—®æ¨¡å¼æ”¯æŒ**

- **RWX**ï¼ˆä¸»è¦ä¼˜åŠ¿ï¼‰
- ROXï¼ˆè‡ªç„¶æ”¯æŒï¼‰
- RWOï¼ˆå¯æ¨¡æ‹Ÿï¼Œä½†éå…¸å‹ï¼‰

**âš ï¸ å±€é™æ€§**

- æ€§èƒ½å— **ç½‘ç»œå»¶è¿Ÿ** å’Œ **NFS Server è´Ÿè½½** å½±å“ï¼ˆå°æ–‡ä»¶æ€§èƒ½å·®ï¼‰
- **å•ç‚¹æ•…éšœé£é™©**ï¼ˆè‹¥ NFS Server æ—  HAï¼‰
- **ä¸€è‡´æ€§æ¨¡å‹è¾ƒå¼±**ï¼šclose-to-open è¯­ä¹‰ï¼Œä¸é€‚åˆå¼ºä¸€è‡´æ€§æ•°æ®åº“
- å®‰å…¨æ€§éœ€æ‰‹åŠ¨åŠ å›ºï¼ˆå¦‚ Kerberosã€IP ç™½åå•ï¼‰

#### 4.1.1 å®‰è£… NFS æœåŠ¡ç«¯è½¯ä»¶åŒ…ï¼ˆæ‰€æœ‰èŠ‚ç‚¹ï¼‰

```bash
$ sudo dnf install -y nfs-utils
```

#### 4.1.2 åˆ›å»ºå…±äº«æ•°æ®æ ¹ç›®å½•ï¼ˆåœ¨NFSæœåŠ¡èŠ‚ç‚¹æ‰§è¡Œï¼‰

```bash
$ sudo mkdir -pv /data/nfs/local
$ sudo chown nobody:nobody /data/nfs/local
```

#### 4.1.3 ç¼–è¾‘æœåŠ¡é…ç½®æ–‡ä»¶ï¼ˆåœ¨NFSæœåŠ¡èŠ‚ç‚¹æ‰§è¡Œï¼‰

é…ç½® NFS æœåŠ¡å™¨æ•°æ®å¯¼å‡ºç›®å½•åŠè®¿é—® NFS æœåŠ¡å™¨çš„å®¢æˆ·ç«¯æœºå™¨æƒé™ã€‚

ç¼–è¾‘é…ç½®æ–‡ä»¶ `vim /etc/exports`ï¼Œæ·»åŠ å¦‚ä¸‹å†…å®¹ï¼š

```bash
# nfsæœåŠ¡ç«¯
$ echo "/data/nfs/local 192.168.200.0/24(rw,sync,all_squash,anonuid=65534,anongid=65534,no_subtree_check)" | sudo tee /etc/exports
```

- /data/nfs/localï¼šNFS å¯¼å‡ºçš„å…±äº«æ•°æ®ç›®å½•
- 192.168.200.0/24ï¼šå¯ä»¥è®¿é—® NFS å­˜å‚¨çš„å®¢æˆ·ç«¯ IP åœ°å€
- rwï¼šè¯»å†™æ“ä½œï¼Œå®¢æˆ·ç«¯æœºå™¨æ‹¥æœ‰å¯¹å·çš„è¯»å†™æƒé™ã€‚
- syncï¼šå†…å­˜æ•°æ®å®æ—¶å†™å…¥ç£ç›˜ï¼Œæ€§èƒ½ä¼šæœ‰æ‰€é™åˆ¶
- all_squashï¼šNFS å®¢æˆ·ç«¯ä¸Šçš„æ‰€æœ‰ç”¨æˆ·åœ¨ä½¿ç”¨å…±äº«ç›®å½•æ—¶éƒ½ä¼šè¢«è½¬æ¢ä¸ºä¸€ä¸ªæ™®é€šç”¨æˆ·çš„æƒé™
- anonuidï¼šè½¬æ¢åçš„ç”¨æˆ·æƒé™ IDï¼Œå¯¹åº”çš„æ“ä½œç³»ç»Ÿçš„ nobody ç”¨æˆ·
- anongidï¼šè½¬æ¢åçš„ç»„æƒé™ IDï¼Œå¯¹åº”çš„æ“ä½œç³»ç»Ÿçš„ nobody ç»„
- no_subtree_checkï¼šä¸æ£€æŸ¥å®¢æˆ·ç«¯è¯·æ±‚çš„å­ç›®å½•æ˜¯å¦åœ¨å…±äº«ç›®å½•çš„å­æ ‘èŒƒå›´å†…ï¼Œä¹Ÿå°±æ˜¯è¯´å³ä½¿è¾“å‡ºç›®å½•æ˜¯ä¸€ä¸ªå­ç›®å½•ï¼ŒNFS æœåŠ¡å™¨ä¹Ÿä¸æ£€æŸ¥å…¶çˆ¶ç›®å½•çš„æƒé™ï¼Œè¿™æ ·å¯ä»¥æé«˜æ•ˆç‡ã€‚

#### 4.1.4 å¯åŠ¨æœåŠ¡å¹¶è®¾ç½®å¼€æœºè‡ªå¯ï¼ˆåœ¨NFSæœåŠ¡èŠ‚ç‚¹æ‰§è¡Œï¼‰

```bash
$ sudo systemctl enable --now rpcbind && sudo systemctl enable --now nfs-server
# é‡æ–°åŠ è½½ NFS å…±äº«é…ç½®ï¼ˆçƒ­åŠ è½½ /etc/expots é…ç½®è€Œæ— éœ€é‡å¯æœåŠ¡ï¼Œæ¯æ¬¡æ¶‰åŠåˆ°è¯¥é…ç½®æ–‡ä»¶ä¿®æ”¹åéƒ½å»ºè®®æ‰§è¡Œä¸€ä¸‹ï¼‰
$ sudo exportfs -r
# æŸ¥çœ‹å…±äº«ç›®å½•å¯¼å‡ºæƒ…å†µ
$ sudo exportfs -v
/data/nfs/local       192.168.200.0/24(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,root_squash,all_squash)
# éªŒè¯
$ sudo exportfs
/data/nfs/local       192.168.200.0/24
# æŸ¥çœ‹NFSç‰ˆæœ¬
$ sudo cat /proc/fs/nfsd/versions
+3 +4 +4.1 +4.2
```

> **åˆ†è§£è¯´æ˜**ï¼š
>
> | å‘½ä»¤éƒ¨åˆ†   | åŠŸèƒ½                              |
> | :--------- | :-------------------------------- |
> | `exportfs` | NFS å…±äº«ç®¡ç†å·¥å…·                  |
> | `-r`       | é‡æ–°å¯¼å‡ºæ‰€æœ‰å…±äº«ï¼ˆre-export allï¼‰ |

#### 4.1.5 é…ç½®NFSä»èŠ‚ç‚¹ï¼ˆä»…NFSå®¢æˆ·ç«¯èŠ‚ç‚¹ï¼‰

- æŸ¥çœ‹NFSç‰ˆæœ¬

```bash
$ mount |grep nfs
sunrpc on /var/lib/nfs/rpc_pipefs type rpc_pipefs (rw,relatime)
192.168.200.116:/data/nfs/local on /data/nfs/local type nfs4 (rw,relatime,vers=4.2,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=192.168.200.117,local_lock=none,addr=192.168.200.116)
```

- æŸ¥çœ‹å¯ä»¥æŒ‚è½½çš„ç›®å½•

```bash
$ showmount -e 192.168.200.116
```

```bash
Export list for 192.168.200.116:
/data/nfs/local 192.168.200.0/24
```

- æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æŒ‚è½½nfsæœåŠ¡å™¨ä¸Šçš„å…±äº«ç›®å½•åˆ°æœ¬æœºè·¯å¾„ /data/nfs/local

```bash
$ sudo mkdir -p /data/nfs/local && sudo mount -t nfs 192.168.200.116:/data/nfs/local /data/nfs/local
```

- å†™å…¥ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶ï¼ˆåœ¨NFSæœåŠ¡ç«¯ï¼‰

```bash
# æ‰§è¡Œå®Œæˆåï¼ŒæŸ¥çœ‹NFSä»èŠ‚ç‚¹åŒæ­¥ç›®å½•ï¼Œå·²ç»ç”Ÿæˆäº† test.txt æ–‡ä»¶
$ echo "hello from nfs server" | sudo tee -a /data/nfs/local/test.txt
```

#### 4.1.6 åŸç”Ÿæ–¹å¼æ•°æ®æŒ‚è½½

##### 4.1.6.1 ä¸€ä¸ªé™æ€é…ç½®æµ‹è¯•

é™æ€é…ç½®æ˜¯æŒ‡ç›´æ¥æŒ‡å®šnfsï¼›åŠ¨æ€é…ç½®æ˜¯æŒ‡é€šè¿‡StorageClassè‡ªåŠ¨åˆ›å»ºpvcï¼Œç»‘å®šåˆ°podã€‚

- é…ç½®nfs-test.yaml

```yaml
tee nfs-test.yaml << EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: nfs-nginx-pv
  name: nfs-nginx-pv
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nfs-nginx-pv
  template:
    metadata:
      labels:
        app: nfs-nginx-pv
    spec:
      containers:
      - image: nginx:1.25.4
        name: nginx
        volumeMounts:
        - name: html
          mountPath: /usr/share/nginx/html
      volumes:
      - name: html
        nfs:
          server: 192.168.200.116
          path: /data/nfs/local/nginx-pv
EOF
```

- åˆ›å»º

```bash
# åœ¨ä»»ä½•NFSèŠ‚ç‚¹åˆ›å»ºç›®å½•ï¼Œè‹¥ä¸åˆ›å»ºï¼Œåœ¨Podçš„Eventsä¼šæŠ¥é”™ï¼š mounting 192.168.200.116:/data/nfs/local/nginx-pv failed, reason given by server: No such file or directory
$ mkdir -p /data/nfs/local/nginx-pv && echo 111222 > /data/nfs/local/nginx-pv/index.html
$ kubectl apply -f nfs-test.yaml
# éªŒè¯
$ curl <nfs-nginx-pv-pod-ip>:<pod-nginx-port>
```

- åˆ é™¤

```bash
$ kubectl delete -f nfs-test.yaml
```

##### 4.1.6.2 åŸç”Ÿæ–¹å¼æ•°æ®æŒ‚è½½çš„é—®é¢˜

- è¢«æŒ‚è½½çš„nfsç›®å½•ï¼Œè¦å…ˆåˆ›å»ºã€‚
- åˆ é™¤éƒ¨ç½²åï¼Œå¹¶ä¸ä¼šè‡ªåŠ¨æ¸…ç†è¢«æŒ‚è½½çš„ç›®å½•åŠå…¶ä¸‹çš„æ–‡ä»¶ã€‚
- æ¯ä¸ªè¢«æŒ‚è½½çš„ç›®å½•å¤§å°ç­‰èµ„æºå¹¶ä¸è¢«é™åˆ¶



### 4.2 å®‰è£…Kubernetes NFS Subdir External Provisionerï¼ˆè¿‡æ—¶ï¼‰

| é¡¹ç›®                                                         | ç±»å‹                        | çŠ¶æ€               | æ¨èåº¦           |
| ------------------------------------------------------------ | --------------------------- | ------------------ | ---------------- |
| [`kubernetes-sigs/nfs-subdir-external-provisioner`](https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner) | Legacy External Provisioner | ç»´æŠ¤ä¸­ï¼ŒåŠŸèƒ½å†»ç»“   | âš ï¸ ä»…é™ç®€å•åœºæ™¯   |
| [`kubernetes-csi/csi-driver-nfs`](https://github.com/kubernetes-csi/csi-driver-nfs) | CSI Driverï¼ˆæ ‡å‡†ï¼‰          | æ´»è·ƒç»´æŠ¤ï¼ŒæŒç»­æ›´æ–° | âœ… æ¨èç”¨äºæ–°é›†ç¾¤ |

https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner

#### 4.2.1 è·å– NFS Subdir External Provisioner éƒ¨ç½²æ–‡ä»¶ï¼ˆåœ¨masterèŠ‚ç‚¹æ‰§è¡Œï¼‰

- ä¸‹è½½

```bash
$ wget https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner/archive/refs/tags/nfs-subdir-external-provisioner-4.0.18.tar.gz
$ tar -zxvf nfs-subdir-external-provisioner-4.0.18.tar.gz
$ cd nfs-subdir-external-provisioner-nfs-subdir-external-provisioner-4.0.18/
```

#### 4.2.2 åˆ›å»º NameSpace

**é»˜è®¤çš„ NameSpace ä¸º default**ï¼Œä¸ºäº†ä¾¿äºèµ„æºåŒºåˆ†ç®¡ç†ï¼Œå¯ä»¥åˆ›å»ºä¸€ä¸ªæ–°çš„å‘½åç©ºé—´ã€‚

- åˆ›å»ºNamespace

```bash
$ kubectl create ns nfs-system
```

- æ›¿æ¢èµ„æºæ¸…å•ä¸­çš„å‘½åç©ºé—´åç§°

```bash
$ sed -i'' "s/namespace:.*/namespace: nfs-system/g" ./deploy/rbac.yaml ./deploy/deployment.yaml
```

#### 4.2.3 é…ç½®å¹¶éƒ¨ç½² RBAC authorization

- åˆ›å»ºRBACèµ„æº

```bash
$ kubectl create -f deploy/rbac.yaml
```

#### 4.2.4 é…ç½®å¹¶éƒ¨ç½² NFS subdir external provisioner

è¯·ä½¿ç”¨ `vi` ç¼–è¾‘å™¨ï¼Œç¼–è¾‘æ–‡ä»¶ `deploy/deployment.yaml`ï¼Œè¯·ç”¨å®é™… NFS æœåŠ¡ç«¯é…ç½®ä¿®æ”¹ä»¥ä¸‹å†…å®¹ï¼š

1. **image:** é»˜è®¤ä½¿ç”¨ registry.k8s.io é•œåƒä»“åº“çš„é•œåƒ `nfs-subdir-external-provisioner:v4.0.2`ï¼Œç½‘ç»œå—é™æ—¶éœ€è¦æƒ³åŠæ³•ä¸‹è½½å¹¶ä¸Šä¼ åˆ°è‡ªå·±çš„é•œåƒä»“åº“

2. **192.168.200.116ï¼š** NFS æœåŠ¡å™¨çš„ä¸»æœºåæˆ–æ˜¯ IP åœ°å€

3. **/data/nfs/local:** NFS æœåŠ¡å™¨å¯¼å‡ºçš„å…±äº«æ•°æ®ç›®å½•çš„è·¯å¾„ï¼ˆexportfsï¼‰

- é…ç½®

```js
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nfs-client-provisioner
  labels:
    app: nfs-client-provisioner
  # replace with namespace where provisioner is deployed
  namespace: nfs-system
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: nfs-client-provisioner
  template:
    metadata:
      labels:
        app: nfs-client-provisioner
    spec:
      serviceAccountName: nfs-client-provisioner
      containers:
        - name: nfs-client-provisioner
          image: registry.k8s.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2
          volumeMounts:
            - name: nfs-client-root
              mountPath: /persistentvolumes
          env:
            - name: PROVISIONER_NAME
              value: k8s-sigs.io/nfs-subdir-external-provisioner
            - name: NFS_SERVER
              value: 192.168.200.116 // [!code focus:1]
            - name: NFS_PATH
              value: /data/nfs/local // [!code focus:1]
      volumes:
        - name: nfs-client-root
          nfs:
            server: 192.168.200.116 // [!code focus:1]
            path: /data/nfs/local // [!code focus:1]
```

- éƒ¨ç½²

```bash
$ kubectl apply -f deploy/deployment.yaml
```

- æŸ¥çœ‹ deploymentã€pod éƒ¨ç½²ç»“æœ

```bash
$ kubectl get deploy,po -n nfs-system
NAME                                     READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nfs-client-provisioner   1/1     1            1           17m

NAME                                          READY   STATUS        RESTARTS   AGE
pod/nfs-client-provisioner-5cd44d94b5-ftqr7   1/1     Running       0          3m53s
```

#### 4.2.5 éƒ¨ç½² Storage Class

**Step 1:** ç¼–è¾‘ NFS subdir external provisioner å®šä¹‰ Kubernetes Storage Class çš„é…ç½®æ–‡ä»¶  `deploy/class.yaml`ï¼Œé‡ç‚¹ä¿®æ”¹ä»¥ä¸‹å†…å®¹ï¼š

- å­˜å‚¨ç±»åç§°
- å­˜å‚¨å·åˆ é™¤åçš„é»˜è®¤ç­–ç•¥

```js
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: nfs-client // [!code --]
  name: nfs-storage // [!code ++]
  annotations: // [!code ++]
    storageclass.kubernetes.io/is-default-class: "false" # ä¸è®¾ä¸ºé»˜è®¤ // [!code ++]
provisioner: k8s-sigs.io/nfs-subdir-external-provisioner # or choose another name, must match deployment's env PROVISIONER_NAME'
parameters:
  archiveOnDelete: "false" // [!code --]
  archiveOnDelete: "true" // [!code ++]
  pathPattern: "${.PVC.namespace}/${.PVC.name}" # è‡ªåŠ¨åˆ›å»ºç›®å½•ç»“æ„ // [!code ++]
```

é‡ç‚¹è¯´è¯´ Parameters archiveOnDelete çš„é…ç½®ã€‚

- è¯¥å€¼ä¸º false æ—¶ï¼Œå­˜å‚¨å·åˆ é™¤æ—¶ï¼Œåœ¨ NFS ä¸Šç›´æ¥åˆ é™¤å¯¹åº”çš„æ•°æ®ç›®å½•
- è¯¥å€¼ä¸º true æ—¶ï¼Œå­˜å‚¨å·åˆ é™¤æ—¶ï¼Œåœ¨ NFS ä¸Šä»¥ `archived-<volume.Name>` çš„å‘½åè§„åˆ™ï¼Œå½’æ¡£ä¿ç•™åŸæœ‰çš„æ•°æ®ç›®å½•
- **å…·ä½“å¦‚ä½•è®¾ç½®è¯·ä¸€å®šç»“åˆè‡ªå·±çš„å®é™…ç¯å¢ƒé…Œæƒ…å¤„ç†**ï¼Œæ•°æ®é‡å°çš„åœºæ™¯ä¸‹ï¼Œä¸ªäººå–œæ¬¢è®¾ç½®ä¸º trueï¼Œæ‰‹åŠ¨æˆ–è‡ªåŠ¨å®šæ—¶æ¸…ç†å½’æ¡£æ•°æ®ã€‚

**Step 2:** æ‰§è¡Œéƒ¨ç½²å‘½ä»¤ï¼Œéƒ¨ç½² Storage Classã€‚

```bash
$ kubectl apply -f deploy/class.yaml
```

- æŸ¥çœ‹ Storage Class éƒ¨ç½²ç»“æœã€‚

```bash
$ kubectl get sc
NAME          PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
nfs-storage   k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           false                  14s
# è‹¥æ— æ³•åˆ›å»ºpvcå¯ä»¥æŸ¥çœ‹ NFS Provisioner æ—¥å¿—
$ kubectl logs -n nfs-system deploy/nfs-client-provisioner
```

### 4.3 NFS CSI Driverï¼ˆv4.3+ï¼‰

https://github.com/kubernetes-csi/csi-driver-nfs

| ç‰¹æ€§           | `nfs-subdir-external-provisioner`                            | NFS CSI Driver                                               |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| å·¥ä½œåŸç†       | Controller ç›‘å¬ PVC â†’ åœ¨ NFS server ä¸Š `mkdir /share/pvc-<id>` â†’ åˆ›å»º PV æŒ‡å‘è¯¥å­ç›®å½• | CSI Node/Controller æ’ä»¶ï¼ŒæŒ‰éœ€ mount NFS è·¯å¾„                |
| åŠ¨æ€ä¾›ç»™       | âœ… è‡ªåŠ¨åˆ›å»ºå­ç›®å½•                                             | âœ… å¯æŒ‚è½½å›ºå®šè·¯å¾„ï¼Œæˆ–é…åˆ `subdir` åŠ¨æ€ç”Ÿæˆå­ç›®å½•ï¼ˆéœ€ v4.3+ï¼‰ |
| å­ç›®å½•éš”ç¦»     | âœ… æ¯ä¸ª PVC ç‹¬ç«‹å­ç›®å½•                                        | âš ï¸ é»˜è®¤æ‰€æœ‰ PVC å…±äº«åŒä¸€è·¯å¾„ï¼ˆé™¤éæ˜¾å¼é…ç½® `subdir`ï¼‰         |
| åˆ é™¤è¡Œä¸º       | å¯é…ç½® `onDelete: delete` åˆ é™¤å­ç›®å½•                         | v4.3+ æ”¯æŒ `onDelete: delete`ï¼ˆ[PR #478](https://github.com/kubernetes-csi/csi-driver-nfs/pull/478)ï¼‰ |
| K8s ç‰ˆæœ¬å…¼å®¹æ€§ | v1.20 ï½ v1.28ï¼ˆv1.29+ å¯èƒ½æœ‰ RBAC é—®é¢˜ï¼‰                    | âœ… å®˜æ–¹æ”¯æŒ v1.20 ï½ v1.32+                                   |
| æ¶æ„æ ‡å‡†       | Legacy external provisioner                                  | âœ… CSIï¼ˆKubernetes å­˜å‚¨æœªæ¥æ ‡å‡†ï¼‰                             |
| å¤šç§Ÿæˆ·éš”ç¦»     | å¼±ï¼ˆé ç›®å½•åéš”ç¦»ï¼‰                                           | åŒå·¦                                                         |
| volume æ‰©å®¹    | âŒ ä¸æ”¯æŒ                                                     | âŒ ä¸æ”¯æŒï¼ˆNFS åè®®é™åˆ¶ï¼‰                                     |
| å¿«ç…§/å…‹éš†      | âŒ                                                            | âŒ                                                            |
| ARM64 æ”¯æŒ     | âœ…ï¼ˆéœ€è‡ªå·±æ„å»ºé•œåƒï¼‰                                          | âœ…ï¼ˆå®˜æ–¹é•œåƒå« multi-archï¼‰                                   |
| Helm Chart     | ç¤¾åŒºç»´æŠ¤                                                     | âœ… å®˜æ–¹æä¾›                                                   |

#### 4.3.1 Helmå®‰è£… CSI Driverï¼ˆæ—  SCï¼‰

https://github.com/kubernetes-csi/csi-driver-nfs/tree/master/charts

- æ·»åŠ èµ„æºåº“

```bash
$ HTTP_PROXY=http://192.168.200.1:7890 \
HTTPS_PROXY=http://192.168.200.1:7890 \
helm repo add csi-driver-nfs https://raw.githubusercontent.com/kubernetes-csi/csi-driver-nfs/master/charts
```

- æŸ¥è¯¢æ‰€æœ‰å¯ç”¨ç‰ˆæœ¬

```bash
$ helm search repo -l csi-driver-nfs
```

- å®‰è£…

```bash
# æ³¨æ„è®¿é—® lb.emon.local ï¼ˆæ§åˆ¶é¢æ¿åŸŸåï¼‰ ä¸è¦ä½¿ç”¨ä»£ç†
$ HTTP_PROXY=http://192.168.200.1:7890 \
HTTPS_PROXY=http://192.168.200.1:7890 \
NO_PROXY="lb.emon.local" \
helm install csi-driver-nfs csi-driver-nfs/csi-driver-nfs \
  --namespace kube-system \
  --version v4.12.1 \
  -f <(cat <<'EOF'
storageClasses:
  - name: nfs-csi-delete
    annotations:
      storageclass.kubernetes.io/is-default-class: "false"
    parameters:
      server: 192.168.200.116
      share: /data/nfs/local
      subdir: "" # æŒ‡å®šä¸ºç©ºï¼Œæˆ–ä¸æŒ‡å®šè¯¥å‚æ•°ï¼Œéƒ½æ˜¯è‡ªåŠ¨ç”Ÿæˆnfséš”ç¦»æ–‡ä»¶
    reclaimPolicy: Delete
    volumeBindingMode: Immediate
    mountOptions:
      - nfsvers=4.2
      - proto=tcp
  - name: nfs-csi-retain
    parameters:
      server: 192.168.200.116
      share: /data/nfs/local
    reclaimPolicy: Retain
    volumeBindingMode: Immediate
    mountOptions:
      - nfsvers=4.2
      - proto=tcp
EOF
)
```

```bash
# æ‰§è¡Œç»“æœï¼Œè‹¥é”™è¯¯ï¼ˆError: INSTALLATION FAILED: Get "https://raw.githubusercontent.com/kubernetes-csi/csi-driver-nfs/master/charts/v4.12.1/csi-driver-nfs-4.12.1.tgz": EOFï¼‰ï¼Œè¯·é‡è¯•
NAME: csi-driver-nfs
LAST DEPLOYED: Sat Jan 24 23:22:50 2026
NAMESPACE: kube-system
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
The CSI NFS Driver is getting deployed to your cluster.

To check CSI NFS Driver pods status, please run:

  kubectl --namespace=kube-system get pods --selector="app.kubernetes.io/instance=csi-driver-nfs" --watch
```

- æŸ¥çœ‹ Pod ä¿¡æ¯

```bash
$ kubectl --namespace=kube-system get pods --selector="app.kubernetes.io/instance=csi-driver-nfs" 
NAME                                 READY   STATUS    RESTARTS   AGE
csi-nfs-controller-94796c4b7-27xdl   5/5     Running   0          5h10m
csi-nfs-node-bx4sk                   3/3     Running   0          5h10m
csi-nfs-node-h2bjz                   3/3     Running   0          5h10m
csi-nfs-node-mvsnm                   3/3     Running   0          5h10m
# æŸ¥è¯¢controller
$ kubectl -n kube-system get pod -o wide -l app=csi-nfs-controller
# æŸ¥è¯¢node
$ kubectl -n kube-system get pod -o wide -l app=csi-nfs-node
# æŸ¥è¯¢sc
$ kubectl get sc
NAME              PROVISIONER        RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
local (default)   openebs.io/local   Delete          WaitForFirstConsumer   false                  2d21h
nfs-csi-delete    nfs.csi.k8s.io     Delete          Immediate              true                   2m59s
nfs-csi-retain    nfs.csi.k8s.io     Retain          Immediate              true                   2m59s
```

#### 4.3.2 Helmå¸è½½CSIé©±åŠ¨

```bash
$ helm uninstall csi-driver-nfs -n kube-system
```

### 4.4 éƒ¨ç½²OpenEBSï¼ˆæ¨èï¼‰

#### 4.4.0 OpenEBS å­˜å‚¨æ–¹æ¡ˆ

OpenEBS æ˜¯ CNCF æ²™ç®±é¡¹ç›®ï¼Œæä¾› **å®¹å™¨åŸç”Ÿå­˜å‚¨**ï¼Œæ”¯æŒå¤šç§åç«¯å¼•æ“ï¼š

| å¼•æ“ç±»å‹       | ç‰¹ç‚¹                                | è®¿é—®æ¨¡å¼ | é€‚ç”¨åœºæ™¯                                   |
| -------------- | ----------------------------------- | -------- | ------------------------------------------ |
| cStor          | å—å­˜å‚¨ + å¿«ç…§ + å¤åˆ¶                | RWO      | ç”Ÿäº§çº§æœ‰çŠ¶æ€åº”ç”¨ï¼ˆMySQLã€ETCDï¼‰            |
| Jiva           | åŸºäº iSCSI çš„è½»é‡å—å­˜å‚¨             | RWO      | å°è§„æ¨¡é›†ç¾¤ã€è¾¹ç¼˜è®¡ç®—                       |
| LocalPV        | ç›´æ¥ä½¿ç”¨æœ¬åœ°ç£ç›˜ï¼ˆHostPath å¢å¼ºç‰ˆï¼‰ | RWO      | é«˜æ€§èƒ½ã€ä½å»¶è¿Ÿåœºæ™¯ï¼ˆå¦‚ Kafkaã€ClickHouseï¼‰ |
| Mayastorï¼ˆæ–°ï¼‰ | åŸºäº SPDK/NVMe çš„é«˜æ€§èƒ½å¼•æ“         | RWO      | è¶…ä½å»¶è¿Ÿã€é«˜ IOPSï¼ˆé‡‘èäº¤æ˜“ã€AIè®­ç»ƒï¼‰      |

**âœ… åŠŸèƒ½ç‰¹ç‚¹**

- **å®Œå…¨è¿è¡Œåœ¨ K8S å†…éƒ¨**ï¼ˆOperator + CSI é©±åŠ¨ï¼‰
- æ”¯æŒ **å¿«ç…§ã€å…‹éš†ã€QoSã€ç›‘æ§**
- cStor/Jiva æ”¯æŒ **è·¨èŠ‚ç‚¹å¤åˆ¶**ï¼ˆæå‡å¯ç”¨æ€§ï¼‰
- LocalPV æ€§èƒ½æ¥è¿‘è£¸é‡‘å±

**ğŸ“Œ é€‚ç”¨åœºæ™¯**

- **æ•°æ®åº“æŒä¹…åŒ–**ï¼ˆMySQLã€PostgreSQLã€MongoDBï¼‰
- **ETCD é›†ç¾¤**ï¼ˆæ¨è LocalPV + SSDï¼‰
- **è¾¹ç¼˜/ç§æœ‰äº‘ç¯å¢ƒ**ï¼ˆæ— äº‘å‚å•†ä¾èµ–ï¼‰
- **éœ€è¦å¿«ç…§ä¸å¤‡ä»½èƒ½åŠ›** çš„ä¸šåŠ¡

**ğŸ”§ è®¿é—®æ¨¡å¼æ”¯æŒ**

- **ä»… RWO**ï¼ˆæ‰€æœ‰ OpenEBS å¼•æ“å‡ä¸æ”¯æŒ RWXï¼‰
  - å› å…¶æœ¬è´¨æ˜¯ **å—å­˜å‚¨** æˆ– **æœ¬åœ°å·**

**âš ï¸ å±€é™æ€§**

- ä¸æ”¯æŒ RWX â†’ æ— æ³•ç”¨äºå¤š Pod å…±äº«å†™å…¥åœºæ™¯
- cStor/Jiva æœ‰é¢å¤– CPU/å†…å­˜å¼€é”€
- LocalPV **ç»‘å®šèŠ‚ç‚¹**ï¼ŒPod è¿ç§»å—é™ï¼ˆéœ€é…åˆè°ƒåº¦å™¨ç­–ç•¥ï¼‰

#### 4.4.1 å®‰è£…

https://openebs.io/

é¦–å…ˆï¼Œè¯·ç¡®ä¿å®‰è£…äº†helmã€‚

- æ·»åŠ helmä»“åº“

```bash
$ helm repo add openebs https://openebs.github.io/charts
# æ›´æ–°ä»“åº“ç´¢å¼•
$ helm repo update
```

- å®‰è£…openebs

```bash
$ helm install openebs openebs/openebs \
  --namespace openebs \
  --create-namespace \
  --version 3.10.0
```

- æŸ¥çœ‹

```bash
$ helm ls -n openebs
NAME    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART           APP VERSION
openebs openebs         1               2025-07-12 05:26:57.179546135 +0800 CST deployed        openebs-3.10.0  3.10.0 

$ kubectl get pods -n openebs
NAME                                           READY   STATUS    RESTARTS   AGE
openebs-localpv-provisioner-668c7d88f6-rdc8r   1/1     Running   0          2m37s
openebs-ndm-operator-57fbd6b955-nhbfn          1/1     Running   0          24m
openebs-ndm-xmxh9                              1/1     Running   0          24m
openebs-ndm-zbbnl                              1/1     Running   0          24m

$ kubectl get sc
NAME               PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
nfs-storage        k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate              false                  111m
openebs-device     openebs.io/local                              Delete          WaitForFirstConsumer   false                  24m
openebs-hostpath   openebs.io/local                              Delete          WaitForFirstConsumer   false                  24m
```

- è®¾ç½®é»˜è®¤å­˜å‚¨ç±»

**å¿…é¡»è¦è®¾ç½®é»˜è®¤å­˜å‚¨ç±»ï¼Œä¸ç„¶å®‰è£…kubesphereçš„æ—¶å€™ï¼Œä¼šæŠ¥é”™ï¼Œæ‰¾ä¸åˆ°é»˜è®¤å­˜å‚¨ç±»**

```bash
$ kubectl patch storageclass openebs-hostpath -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'

$ kubectl get sc
NAME                         PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
nfs-storage                  k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate              false                  117m
openebs-device               openebs.io/local                              Delete          WaitForFirstConsumer   false                  30m
openebs-hostpath (default)   openebs.io/local                              Delete          WaitForFirstConsumer   false                  30m
```

### 4.5 CephFS

æš‚æ— 

### 4.6 å­˜å‚¨æ–¹æ¡ˆå¯¹æ¯”ä¸é€‰æ‹©

<span style="color:#32CD32;font-weight:bold;">**â€œOpenEBS ä¸“æ³¨é«˜æ€§èƒ½ RWO åœºæ™¯ï¼ˆå¦‚æ•°æ®åº“ï¼‰ï¼ŒNFS è¦†ç›–å…±äº« RWX éœ€æ±‚ï¼ˆå¦‚ CMSï¼‰ï¼ŒäºŒè€…äº’è¡¥ç»„æˆ Kubernetes å­˜å‚¨çš„é»„é‡‘æ­æ¡£ã€‚â€**</span>

#### 4.6.1 èƒ½åŠ›å¯¹æ¯”è¡¨

| ç»´åº¦         | NFS                | OpenEBS (cStor) | OpenEBS (LocalPV) | Longhorn     | CephFS                               |
| ------------ | ------------------ | --------------- | ----------------- | ------------ | ------------------------------------ |
| å­˜å‚¨ç±»å‹     | æ–‡ä»¶               | å—              | å—/æ–‡ä»¶ï¼ˆæœ¬åœ°ï¼‰   | å—           | æ–‡ä»¶ï¼ˆåˆ†å¸ƒå¼ï¼‰                       |
| RWX æ”¯æŒ     | âœ…âœ…âœ…                | âŒ               | âŒ                 | âŒ            | âœ…âœ…âœ…                                  |
| RWO æ€§èƒ½     | ä¸­ï¼ˆç½‘ç»œç“¶é¢ˆï¼‰     | ä¸­é«˜            | æé«˜ï¼ˆæœ¬åœ° SSDï¼‰  | ä¸­é«˜         | ä¸­é«˜ï¼ˆä¼˜äº NFSï¼Œä¾èµ–ç½‘ç»œä¸ OSDï¼‰     |
| é«˜å¯ç”¨       | ä¾èµ– NFS Server HA | å†…ç½®å‰¯æœ¬        | æ— ï¼ˆèŠ‚ç‚¹ç»‘å®šï¼‰    | å†…ç½®å‰¯æœ¬     | âœ…âœ…âœ…ï¼ˆå¤š MDS + å¤šå‰¯æœ¬/ECï¼‰            |
| å¿«ç…§/å¤‡ä»½    | âŒ                  | âœ…               | âŒ/æœ‰é™            | âœ…âœ…           | âœ…ï¼ˆæ”¯æŒå·çº§å¿«ç…§ï¼‰                    |
| è¿ç»´å¤æ‚åº¦   | ä¸­ï¼ˆéœ€ç»´æŠ¤ NFSï¼‰   | ä¸­              | ä½                | ä½           | é«˜ï¼ˆéœ€éƒ¨ç½² MON/OSD/MDSï¼Œè°ƒä¼˜ CRUSHï¼‰ |
| é€‚ç”¨ç¯å¢ƒ     | æ··åˆäº‘/ç§æœ‰äº‘      | ç§æœ‰äº‘/è¾¹ç¼˜     | é«˜æ€§èƒ½ç§æœ‰äº‘      | ä¸­å°ç”Ÿäº§é›†ç¾¤ | å¤§è§„æ¨¡ç§æœ‰äº‘ã€éœ€è¦ RWX + ä¼ä¸šçº§èƒ½åŠ›  |
| æ˜¯å¦å¼€æºå…è´¹ | æ˜¯ï¼ˆNFS åè®®ï¼‰     | æ˜¯              | æ˜¯                | æ˜¯           | æ˜¯ï¼ˆCeph å®Œå…¨å¼€æºï¼‰                  |

#### 4.6.2 å¸¸è§åœºæ™¯æ¨èè¡¨

- **Kubernetes å­˜å‚¨æ–¹æ¡ˆå¯¹æ¯”æ€»ç»“è¡¨**

| ä½¿ç”¨åœºæ™¯                | æ¨èæ–¹æ¡ˆ                     | æ”¯æŒçš„è®¿é—®æ¨¡å¼ï¼ˆAccess Modesï¼‰                               | å…³é”®ç†ç”±                                                |
| ----------------------- | ---------------------------- | ------------------------------------------------------------ | ------------------------------------------------------- |
| é«˜æ€§èƒ½æ•°æ®åº“            | OpenEBS (LocalPV / cStor)    | LocalPV: RWO cStor (å—è®¾å¤‡): RWO                             | ä½å»¶è¿Ÿã€é«˜ IOPSï¼›æœ¬åœ°ç›´é€šæˆ–å¯æ§å‰¯æœ¬ï¼›ä¸ä¾èµ–ç½‘ç»œæ–‡ä»¶ç³»ç»Ÿ |
| å…±äº«æ–‡ä»¶å­˜å‚¨            | NFS / CephFS                 | RWX, ROX, RWOï¼ˆä¸‰è€…å‡æ”¯æŒï¼‰                                  | å¤š Pod åŒæ—¶è¯»å†™åŒä¸€å·ï¼›NFS ç®€å•ï¼ŒCephFS å¯æ‰©å±•          |
| è¾¹ç¼˜è®¡ç®— / èµ„æºå—é™ç¯å¢ƒ | OpenEBS (LocalPV)            | RWO                                                          | é›¶å¤–éƒ¨ä¾èµ–ã€è½»é‡ã€èµ„æºå¼€é”€æå°                          |
| ä¼ä¸šå†…å®¹ç®¡ç†ç³»ç»Ÿï¼ˆCMSï¼‰ | NFS                          | RWX, ROX, RWO                                                | æ˜“é›†æˆã€ç¨³å®šã€æ”¯æŒå¤šå®ä¾‹å…±äº«ä¸Šä¼ ç›®å½•                    |
| å¤šé›†ç¾¤ / æ··åˆäº‘éƒ¨ç½²     | OpenEBS (cStor/Jiva/LocalPV) | Jiva/cStor: RWO LocalPV: RWO ï¼ˆæ³¨ï¼šOpenEBS é»˜è®¤ä¸æ”¯æŒ RWXï¼Œé™¤éä½¿ç”¨ Mayastor + NVMe-oF æˆ–ç¬¬ä¸‰æ–¹æ–¹æ¡ˆï¼‰ | äº‘åŸç”Ÿã€å¯éšåº”ç”¨éƒ¨ç½²åˆ°ä»»æ„é›†ç¾¤ï¼›æ— éœ€å…±äº«å­˜å‚¨åŸºç¡€è®¾æ–½    |
| å¼€å‘æµ‹è¯•ç¯å¢ƒ            | NFS / OpenEBS (LocalPV)      | NFS: RWX, ROX, RWO LocalPV: RWO                              | NFS å¿«é€Ÿå…±äº«æ•°æ®ï¼›LocalPV é€‚åˆä¸´æ—¶ã€éš”ç¦»æµ‹è¯•            |

- **å„æ–¹æ¡ˆå¯¹è®¿é—®æ¨¡å¼çš„åŸç”Ÿæ”¯æŒ**

| å­˜å‚¨æ–¹æ¡ˆ                   | RWO  | ROX                     | RWX                         | è¯´æ˜                                                     |
| -------------------------- | ---- | ----------------------- | --------------------------- | -------------------------------------------------------- |
| NFS                        | âœ…    | âœ…                       | âœ…                           | æ‰€æœ‰æ¨¡å¼å¤©ç„¶æ”¯æŒï¼Œæœ€å¸¸ç”¨çš„ RWX æ–¹æ¡ˆä¹‹ä¸€                  |
| CephFS                     | âœ…    | âœ…                       | âœ…                           | å®Œæ•´ POSIX å…¼å®¹ï¼Œä¸‰è€…å‡æ”¯æŒï¼ŒRWX æ€§èƒ½å–å†³äº MDS æ‰©å±•èƒ½åŠ› |
| OpenEBS - LocalPV          | âœ…    | âŒ                       | âŒ                           | ç»‘å®šå•èŠ‚ç‚¹ï¼Œä»…æ”¯æŒ RWO                                   |
| OpenEBS - cStor / Jiva     | âœ…    | âŒï¼ˆCSI é€šå¸¸ä¸æš´éœ² ROXï¼‰ | âŒ                           | åŸºäº iSCSI/iSCSI-like å—è®¾å¤‡ï¼Œä»…æ”¯æŒ RWO                 |
| OpenEBS - Mayastorï¼ˆé«˜çº§ï¼‰ | âœ…    | âŒ                       | âš ï¸ï¼ˆå®éªŒæ€§ RWX via NVMe-oFï¼‰ | é«˜æ€§èƒ½ä½†éƒ¨ç½²å¤æ‚ï¼Œå°šæœªä¸»æµ                               |

> ğŸ“Œ **æ³¨æ„**ï¼šKubernetes ä¸­ **ROXï¼ˆReadOnlyManyï¼‰** å®é™…ä½¿ç”¨è¾ƒå°‘ï¼Œå¤šæ•°â€œåªè¯»å…±äº«â€åœºæ™¯å¯é€šè¿‡ ConfigMap/Secret æˆ–åˆå§‹åŒ–å®¹å™¨å®ç°ã€‚

#### 4.6.3 **ç»“è®º**

- è‹¥éœ€è¦ **RWX** â†’ ä¼˜å…ˆè€ƒè™‘ **NFS**ï¼ˆç®€å•ï¼‰æˆ– **CephFS**ï¼ˆå¤§è§„æ¨¡/é«˜å¯ç”¨ï¼‰ã€‚
- è‹¥è¿½æ±‚ **æè‡´æ€§èƒ½æˆ–è½»é‡åŒ–** â†’ **OpenEBS LocalPVï¼ˆRWOï¼‰** æ˜¯é¦–é€‰ã€‚
- **CephFS è™½å…¨èƒ½ï¼Œä½†å› å¤æ‚åº¦é«˜ï¼Œåœ¨éå¿…è¦åœºæ™¯å¸¸è¢«æ›´ç®€å•çš„æ–¹æ¡ˆæ›¿ä»£**ã€‚



## 5 Harboré•œåƒç§æœ

[Harborå®˜ç½‘](https://goharbor.io/)

[Harbor Github](https://github.com/goharbor/harbor)

[ä¸º arm æ¶æ„æ„å»º Harbor](https://github.com/goharbor/harbor-arm)

### 5.1 åœ¨dockerä¸Šå®‰è£…

#### 5.1.1 å®‰è£…docker-compose

1ï¼šä¸‹è½½

```bash
$ curl -L "https://github.com/docker/compose/releases/download/v2.38.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
```

2ï¼šæ·»åŠ å¯æ‰§è¡Œæƒé™

```bash
$ chmod +x /usr/local/bin/docker-compose
# åˆ›å»ºè½¯è¿ï¼Œé¿å…å®‰è£…Harboræ—¶æŠ¥é”™ï¼š? Need to install docker-compose(1.18.0+) by yourself first and run this script again.
$ ln -snf /usr/local/bin/docker-compose /usr/bin/docker-compose
```

33ï¼šæµ‹è¯•

```bash
$ docker-compose --version
# å‘½ä»¤è¡Œè¾“å‡ºç»“æœ
Docker Compose version v2.38.2
```

#### 5.1.2 å®‰è£…Harboré•œåƒç§æœ(docker+amd64ç‰ˆï¼‰

Harboré•œåƒç§æœï¼ˆ<span style="color:#9400D3;font-weight:bold;">åœ¨emonä¸»æœºrootç”¨æˆ·å®‰è£…</span>ï¼‰

1. ä¸‹è½½åœ°å€

https://github.com/goharbor/harbor/releases

```bash
$ wget https://github.com/goharbor/harbor/releases/download/v2.2.4/harbor-offline-installer-v2.2.4.tgz
```

2. åˆ›å»ºè§£å‹ç›®å½•

```bash
# åˆ›å»ºHarborè§£å‹ç›®å½•
$ mkdir /usr/local/Harbor
# åˆ›å»ºHarborçš„volumeç›®å½•
$ mkdir -p /usr/local/dockerv/harbor_home
```

3. è§£å‹

```bash
# æ¨èv2.2.4ç‰ˆæœ¬ï¼Œæ›´é«˜ç‰ˆæœ¬æ¯”å¦‚2.3å’Œ2.4æœ‰docker-compose down -v ==> down-compose up -dæ—¶postgresqlæœåŠ¡å¯åŠ¨ä¸äº†çš„bugï¼Œæ•°æ®åº“é‡å¯å¤±è´¥ï¼
$ tar -zxvf harbor-offline-installer-v2.2.4.tgz -C /usr/local/Harbor/
$ ls /usr/local/Harbor/harbor
common.sh  harbor.v2.2.4.tar.gz  harbor.yml.tmpl  install.sh  LICENSE  prepare
```

4. åˆ›å»ºè‡ªç­¾åè¯ä¹¦ã€å‚è€ƒå®ç°ï¼Œå»ºè®®èµ°æ­£è§„æ¸ é“çš„CAè¯ä¹¦ã€‘ã€ç¼ºå°‘è¯ä¹¦æ— æ³•æµè§ˆå™¨ç™»å½•ã€‘

- åˆ›å»ºè¯ä¹¦å­˜æ”¾ç›®å½•

```bash
# åˆ‡æ¢ç›®å½•
$ mkdir /usr/local/Harbor/cert && cd /usr/local/Harbor/cert
```

- åˆ›å»ºCAæ ¹è¯ä¹¦

```bash
# å…¶ä¸­Cæ˜¯Countryï¼ŒSTæ˜¯Stateï¼ŒLæ˜¯localï¼ŒOæ˜¯Origanizationï¼ŒOUæ˜¯Organization Unitï¼ŒCNæ˜¯common name(eg, your name or your server's hostname)
$ openssl req -newkey rsa:4096 -nodes -sha256 -keyout ca.key -x509 -days 3650 -out ca.crt \
-subj "/C=CN/ST=ZheJiang/L=HangZhou/O=HangZhou emon Technologies,Inc./OU=IT emon/CN=emon"
# æŸ¥çœ‹ç»“æœ
$ ls
ca.crt  ca.key
```

- ç”Ÿæˆä¸€ä¸ªè¯ä¹¦ç­¾åï¼Œè®¾ç½®è®¿é—®åŸŸåä¸º emon

```bash
$ openssl req -newkey rsa:4096 -nodes -sha256 -keyout emon.key -out emon.csr \
-subj "/C=CN/ST=ZheJiang/L=HangZhou/O=HangZhou emon Technologies,Inc./OU=IT emon/CN=emon"
# æŸ¥çœ‹ç»“æœ
$ ls
ca.crt  ca.key  emon.csr  emon.key
```

- ç”Ÿæˆä¸»æœºçš„è¯ä¹¦

```bash
$ openssl x509 -req -days 3650 -in emon.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out emon.crt
# æŸ¥çœ‹ç»“æœ
$ ls
ca.crt  ca.key  ca.srl  emon.crt  emon.csr  emon.key
```

5. ç¼–è¾‘é…ç½®

```bash
$ cp /usr/local/Harbor/harbor/harbor.yml.tmpl /usr/local/Harbor/harbor/harbor.yml
$ vim /usr/local/Harbor/harbor/harbor.yml
```

```yaml
# ä¿®æ”¹
# hostname: reg.mydomain.com
hostname: 192.168.200.116
# ä¿®æ”¹
  # port: 80
  port: 5080
# ä¿®æ”¹
https:
  # https port for harbor, default is 443
  port: 5443
  # The path of cert and key files for nginx
  # certificate: /your/certificate/path
  # private_key: /your/private/key/path
  # ä¿®æ”¹ï¼šæ³¨æ„ï¼Œè¿™é‡Œä¸èƒ½ä½¿ç”¨è½¯è¿æ¥ç›®å½• /usr/loca/harboræ›¿æ¢/usr/local/Harbor/harbor-2.2.4
  # å¦åˆ™ä¼šå‘ç”Ÿè¯ä¹¦æ‰¾ä¸åˆ°é”™è¯¯ï¼šFileNotFoundError: [Errno 2] No such file or directory: 
  certificate: /usr/local/Harbor/cert/emon.crt
  private_key: /usr/local/Harbor/cert/emon.key
# ä¿®æ”¹
# data_volume: /data
data_volume: /usr/local/dockerv/harbor_home
```

6. å®‰è£…

```bash
# å®‰è£…æ—¶ï¼Œç¡®ä¿ /usr/bin/docker-compose å­˜åœ¨ï¼Œå¦åˆ™ä¼šæŠ¥é”™ï¼š? Need to install docker-compose(1.18.0+) by yourself first and run this script again.
$ /usr/local/Harbor/harbor/install.sh --with-chartmuseum --with-trivy
# åˆ‡æ¢ç›®å½•
$ cd /usr/local/Harbor/harbor/
```

```bash
# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
$ docker-compose ps
# å‘½ä»¤è¡Œè¾“å‡ºç»“æœ
      Name                     Command                  State                           Ports                     
------------------------------------------------------------------------------------------------------------------
chartmuseum         ./docker-entrypoint.sh           Up (healthy)                                                 
harbor-core         /harbor/entrypoint.sh            Up (healthy)                                                 
harbor-db           /docker-entrypoint.sh 96 13      Up (healthy)                                                 
harbor-jobservice   /harbor/entrypoint.sh            Up (healthy)                                                 
harbor-log          /bin/sh -c /usr/local/bin/ ...   Up (healthy)   127.0.0.1:1514->10514/tcp                     
harbor-portal       nginx -g daemon off;             Up (healthy)                                                 
nginx               nginx -g daemon off;             Up (healthy)   0.0.0.0:5080->8080/tcp, 0.0.0.0:5443->8443/tcp
redis               redis-server /etc/redis.conf     Up (healthy)                                                 
registry            /home/harbor/entrypoint.sh       Up (healthy)                                                 
registryctl         /home/harbor/start.sh            Up (healthy)                                                 
trivy-adapter       /home/scanner/entrypoint.sh      Up (healthy)
```

7. æ›´æ–°harbor.ymlé…ç½®

```bash
# è‹¥harbor.ymlæ›´æ–°åï¼Œå¦‚ä¸‹æ‰§è¡Œæ‰ç”Ÿæ•ˆ
# åˆ‡æ¢ç›®å½•
$ cd /usr/local/Harbor/harbor/
# é‡æ–°ç”Ÿæˆdocker-compose.yaml
$ sh prepare
# ç§»é™¤å®¹å™¨å’Œå…³è”èµ„æºï¼›-v è¡¨ç¤ºåˆ é™¤Composeæ–‡ä»¶çš„volumeséƒ¨åˆ†ä¸­å£°æ˜çš„å‘½åå·å’Œé™„åŠ åˆ°å®¹å™¨çš„åŒ¿åå·ï¼Œæ¨èç”¨ -vï¼Œé™¤éæœ‰ç‰¹æ®ŠåŒ¿åå·æ•°æ®éœ€ä¿ç•™
$ nerdctl compose down -v
# åˆ›å»ºå¹¶å¯åŠ¨å®¹å™¨
$ nerdctl compose up -d
```

8. ç™»å½•

è®¿é—®ï¼šhttp://192.168.200.116:5080 ï¼ˆä¼šè¢«è·³è½¬åˆ°http://192.168.200.116:5443ï¼‰

ç”¨æˆ·åå¯†ç ï¼š admin/Harbor12345

<span style="color:red;font-weight:bold;">ç™»å½•æ—¶å¦‚æœæç¤ºï¼šç”¨æˆ·åæˆ–è€…å¯†ç ä¸æ­£ç¡®ï¼Œåœ¨ç¡®è®¤ç”¨æˆ·åå¯†ç æ­£ç¡®çš„æƒ…å†µä¸‹ï¼Œè¯·æ¸…ç†æµè§ˆå™¨ç¼“å­˜ï¼ï¼ï¼</span>

harboræ•°æ®åº“å¯†ç ï¼š root123

ç™»å½•ååˆ›å»ºäº†ç”¨æˆ·ï¼šemon/Emon@123

ç™»å½•ååˆ›å»ºäº†å‘½åç©ºé—´ï¼šdevops-learning å¹¶å°†emonç”¨æˆ·ç”¨äºè¯¥å‘½åç©ºé—´

9. ä¿®æ”¹é…ç½®é‡å¯

```bash
$ cd /usr/local/Harbor/harbor/
$ docker-compose down -v
# å¦‚æœç¢°åˆ° postgresql æœåŠ¡ä¸æ˜¯UPçŠ¶æ€ï¼Œå¯¼è‡´ç™»å½•æç¤ºï¼šæ ¸å¿ƒæœåŠ¡ä¸å¯ç”¨ã€‚ è¯·æ‰§è¡Œä¸‹é¢å‘½ä»¤ï¼ˆæ ¹æ®data_volumeé…ç½®è°ƒæ•´è·¯å¾„ï¼‰ï¼Œè¿™ä¸ªæ˜¯è¯¥ç‰ˆæœ¬çš„bugã€‚ç›®å‰ï¼Œv2.2.4ç‰ˆæœ¬å¯ä»¥æ­£ç¡®é‡å¯ï¼Œæ— éœ€åˆ é™¤pg13
# [emon@emon harbor]$ sudo rm -rf /usr/local/dockerv/harbor_home/database/pg13
$ docker-compose up -d
```

10. ç§æœå®‰å…¨æ§åˆ¶

- å¯¹æ–‡ä»¶ `/etc/docker/daemon.json` è¿½åŠ  `insecure-registries`å†…å®¹ï¼š

```bash
$ vim /etc/docker/daemon.json
```

```bash
{
  "registry-mirrors": ["https://pyk8pf3k.mirror.aliyuncs.com","https://dockerproxy.com","https://mirror.baidubce.com","https://docker.nju.edu.cn","https://docker.mirrors.sjtug.sjtu.edu.cn","https://docker.mirrors.ustc.edu.cn"],
  "graph": "/usr/local/lib/docker",
  "exec-opts": ["native.cgroupdriver=cgroupfs"],
  "insecure-registries": ["192.168.200.116:5080"]
}
```

- å¯¹æ–‡ä»¶ `/lib/systemd/system/docker.service` è¿½åŠ `EnvironmentFile`ï¼šã€å¯çœç•¥ã€‘

```bash
$ vim /lib/systemd/system/docker.service 
```

```bash
# åœ¨ExecStartåé¢ä¸€è¡Œè¿½åŠ ï¼šç»éªŒè¯daemon.jsoné…ç½®äº†insecure-registrieså³å¯ï¼Œæ— éœ€è¿™é‡Œå†é…ç½®
EnvironmentFile=-/etc/docker/daemon.json
```

é‡å¯DockeræœåŠ¡ï¼š

```bash
$ systemctl daemon-reload
$ systemctl restart docker
```

10. æ¨é€é•œåƒ

ç™»å½•harboråï¼Œå…ˆåˆ›å»ºdevops-learningé¡¹ç›®ï¼Œå¹¶åˆ›å»ºemonç”¨æˆ·ã€‚

```bash
# ä¸‹è½½
$ docker pull openjdk:8-jre
# æ‰“æ ‡ç­¾
$ docker tag openjdk:8-jre 192.168.200.116:5080/devops-learning/openjdk:8-jre
# ç™»å½•
$ docker login -u emon -p Emon@123 192.168.200.116:5080
# ä¸Šä¼ é•œåƒ
$ docker push 192.168.200.116:5080/devops-learning/openjdk:8-jre
# é€€å‡ºç™»å½•
$ docker logout 192.168.200.116:5080

æœºå™¨äººè´¦æˆ·ï¼š
tokenï¼š  
XsttKM4zpuFWcchUmEhJErmiRRRfBu0A
```

### 5.2 åœ¨containerdä¸Šå®‰è£…

#### 5.2.1 å®‰è£…nerdctlï¼ˆéšå«nerdctl compose)

<span style="color:red;font-weight:bold;">ç³»ç»Ÿä½¿ç”¨çš„containerdï¼Œè€Œä¸æ˜¯dockerï¼Œè¯·å®‰è£…nerdctl</span>ï¼ˆ**containerd çš„ Docker CLI æ›¿ä»£å·¥å…·**ï¼‰

```bash
# ä¸‹è½½ ARM64 ç‰ˆ nerdctlï¼ˆå…¼å®¹ containerd 1.7.13ï¼‰
$ wget https://github.com/containerd/nerdctl/releases/download/v2.1.3/nerdctl-2.1.3-linux-arm64.tar.gz
$ tar Cxzvf /usr/local/bin nerdctl-2.1.3-linux-arm64.tar.gz
# éªŒè¯å®‰è£…
$ nerdctl --version
nerdctl version 2.1.3
$ nerdctl compose version
nerdctl Compose version v2.1.3
```

#### 5.2.2 å®‰è£…Harboré•œåƒç§æœï¼ˆcontainerd+arm64ç‰ˆï¼‰

Harboré•œåƒç§æœï¼ˆ<span style="color:#9400D3;font-weight:bold;">åœ¨emonä¸»æœºrootç”¨æˆ·å®‰è£…</span>ï¼‰

1. ä¸‹è½½åœ°å€

https://github.com/IabSDocker/harbor/releases

```bash
$ wget https://github.com/IabSDocker/harbor/releases/download/v2.13.1/harbor-offline-installer-v2.13.1_arm64.tgz
```

2. åˆ›å»ºè§£å‹ç›®å½•

```bash
# åˆ›å»ºHarborè§£å‹ç›®å½•
$ mkdir /usr/local/Harbor
# åˆ›å»ºHarborçš„volumeç›®å½•
$ mkdir -p /usr/local/dockerv/harbor_home
```

3. è§£å‹

```bash
$ tar -zxvf harbor-offline-installer-v2.13.1_arm64.tgz -C /usr/local/Harbor/
$ ls /usr/local/Harbor/harbor
common.sh  harbor.v2.13.1.tar.gz  harbor.yml.tmpl  install.sh  LICENSE  prepare
```

4. å‡†å¤‡é…ç½®æ–‡ä»¶

```bash
$ cp /usr/local/Harbor/harbor/harbor.yml.tmpl /usr/local/Harbor/harbor/harbor.yml
```

5. åˆ›å»ºè‡ªç­¾åè¯ä¹¦ã€å‚è€ƒå®ç°ï¼Œå»ºè®®èµ°æ­£è§„æ¸ é“çš„CAè¯ä¹¦ã€‘ã€ç¼ºå°‘è¯ä¹¦æ— æ³•æµè§ˆå™¨ç™»å½•ã€‘

- åˆ›å»ºè¯ä¹¦å­˜æ”¾ç›®å½•

```bash
# åˆ‡æ¢ç›®å½•
$ mkdir /usr/local/Harbor/cert && cd /usr/local/Harbor/cert
```

- åˆ›å»ºCAæ ¹è¯ä¹¦

```bash
# å…¶ä¸­Cæ˜¯Countryï¼ŒSTæ˜¯Stateï¼ŒLæ˜¯localï¼ŒOæ˜¯Origanizationï¼ŒOUæ˜¯Organization Unitï¼ŒCNæ˜¯common name(eg, your name or your server's hostname)
$ openssl req -newkey rsa:4096 -nodes -sha256 -keyout ca.key -x509 -days 3650 -out ca.crt \
-subj "/C=CN/ST=ZheJiang/L=HangZhou/O=HangZhou emon Technologies,Inc./OU=IT emon/CN=emon"
# æŸ¥çœ‹ç»“æœ
$ ls
ca.crt  ca.key
```

- ç”Ÿæˆä¸€ä¸ªè¯ä¹¦ç­¾åï¼Œè®¾ç½®è®¿é—®åŸŸåä¸º emon

```bash
$ openssl req -newkey rsa:4096 -nodes -sha256 -keyout emon.key -out emon.csr \
-subj "/C=CN/ST=ZheJiang/L=HangZhou/O=HangZhou emon Technologies,Inc./OU=IT emon/CN=emon"
# æŸ¥çœ‹ç»“æœ
$ ls
ca.crt  ca.key  emon.csr  emon.key
```

- ç”Ÿæˆä¸»æœºçš„è¯ä¹¦

```bash
$ openssl x509 -req -days 3650 -in emon.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out emon.crt
# æŸ¥çœ‹ç»“æœ
$ ls
ca.crt  ca.key  ca.srl  emon.crt  emon.csr  emon.key
```

##### 5.2.2.1 ä»…httpæ¨¡å¼ã€å†…ç½‘æ¨èã€‘

1. ç¼–è¾‘é…ç½®ï¼Œä»…httpæ¨¡å¼

```bash
$ vim /usr/local/Harbor/harbor/harbor.yml
```

```yml
# Configuration file of Harbor

# The IP address or hostname to access admin UI and registry service.
# DO NOT use localhost or 127.0.0.1, because Harbor needs to be accessed by external clients.
hostname: reg.mydomain.com # [!code --] [!code focus:2]
hostname: 192.168.200.116 # [!code ++]

# http related config
http:
  # port for http, default is 80. If https enabled, this port will redirect to https port
  port: 80 # [!code --] [!code focus:2]
  port: 5080

# https related config
https: # [!code --] [!code focus:1]
  # https port for harbor, default is 443
  port: 443 # [!code --] [!code focus:1]
  # The path of cert and key files for nginx
  certificate: /your/certificate/path # [!code --] [!code focus:2]
  private_key: /your/private/key/path # [!code --] 
  # enable strong ssl ciphers (default: false)
  # strong_ssl_ciphers: false
......
# The default data volume
data_volume: /data # [!code --] [!code focus:2]
data_volume: /usr/local/dockerv/harbor_home # [!code ++]
......
```

2. å®‰è£…

```bash
# åˆ‡æ¢ç›®å½•
$ cd /usr/local/Harbor/harbor/
# åŠ è½½ ARM æ¶æ„çš„ Harbor é•œåƒ
$ nerdctl load -i harbor.v2.13.1.tar.gz
# æ›¿æ¢dockerå‘½ä»¤åˆ°nerdctl
$ sed -i.bak s/docker/nerdctl/ prepare 
# ç”Ÿæˆdocker-compose.yaml
$ sh prepare
# è‹¥ä¸æ˜¯ç¬¬ä¸€æ¬¡å¯åŠ¨ï¼Œç§»é™¤å®¹å™¨å’Œå…³è”èµ„æº
# -v è¡¨ç¤ºåˆ é™¤Composeæ–‡ä»¶çš„volumeséƒ¨åˆ†ä¸­å£°æ˜çš„å‘½åå·å’Œé™„åŠ åˆ°å®¹å™¨çš„åŒ¿åå·ï¼Œæ¨èç”¨ -vï¼Œé™¤éæœ‰ç‰¹æ®ŠåŒ¿åå·æ•°æ®éœ€ä¿ç•™
$ nerdctl compose down -v
# åˆ›å»ºå¹¶å¯åŠ¨å®¹å™¨
$ nerdctl compose up -d
```

è®¿é—®ï¼šhttp://192.168.200.116:5080

ç”¨æˆ·åå¯†ç ï¼š admin/Harbor12345

<span style="color:red;font-weight:bold;">ç™»å½•æ—¶å¦‚æœæç¤ºï¼šç”¨æˆ·åæˆ–è€…å¯†ç ä¸æ­£ç¡®ï¼Œåœ¨ç¡®è®¤ç”¨æˆ·åå¯†ç æ­£ç¡®çš„æƒ…å†µä¸‹ï¼Œè¯·æ¸…ç†æµè§ˆå™¨ç¼“å­˜ï¼ï¼ï¼</span>

3. containerdé…ç½®ï¼ˆæ‰€æœ‰èŠ‚ç‚¹ï¼‰

<span style="color:#9400D3;font-weight:bold;">è¿™ä¸ªé…ç½®å¯¹ctrã€nerdctlæ— æ•ˆï¼Œä½†å¯¹crictlç”Ÿæ•ˆ</span>ï¼ˆæ‰€æœ‰èŠ‚ç‚¹ï¼‰

- é…ç½®

```bash
$ vim /etc/containerd/config.toml
```

```toml
[plugins]
  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
    runtime_type = "io.containerd.runc.v2"
    [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
      SystemdCgroup = true
  [plugins."io.containerd.grpc.v1.cri"]
    sandbox_image = "registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.9"
    [plugins."io.containerd.grpc.v1.cri".cni]
      bin_dir = "/opt/cni/bin"
      conf_dir = "/etc/cni/net.d"
      max_conf_num = 1
      conf_template = ""
    [plugins."io.containerd.grpc.v1.cri".registry]
        [plugins."io.containerd.grpc.v1.cri".registry.mirrors] // [!code --] [!code focus:2]
      [plugins."io.containerd.grpc.v1.cri".registry.mirrors] // [!code ++]
        [plugins."io.containerd.grpc.v1.cri".registry.mirrors."docker.io"]
          endpoint = ["https://registry-1.docker.io"]
        [plugins."io.containerd.grpc.v1.cri".registry.mirrors."192.168.200.116:5080"] // [!code ++] [!code focus:2]
          endpoint = ["http://192.168.200.116:5080"] // [!code ++]
```

- é‡å¯

```bash
$ sudo systemctl restart containerd
```

4. æ¨é€é•œåƒ

- ä½¿ç”¨nerdctl

```bash
# ä¸‹è½½
$ https_proxy=http://192.168.200.1:7890 nerdctl pull openjdk:8-jre
# æ‰“æ ‡ç­¾
$ nerdctl tag openjdk:8-jre 192.168.200.116:5080/library/openjdk:8-jre
# ç™»å½•ï¼Œç™»å½•åä¿¡æ¯å­˜å‚¨åœ¨ç”¨æˆ·ç›®å½•ä¸‹çš„ .docker/config.json
# --insecure-registry å‘Šè¯‰ nerdctl å…è®¸ä½¿ç”¨ HTTP è¿æ¥ï¼ˆå¦åˆ™é»˜è®¤å¼ºåˆ¶ HTTPSï¼‰ã€‚
$ echo "Harbor12345" | nerdctl login --insecure-registry -u admin --password-stdin 192.168.200.116:5080
# ä¸Šä¼ é•œåƒ
$ nerdctl push --insecure-registry 192.168.200.116:5080/library/openjdk:8-jre
# é€€å‡ºç™»å½•
$ nerdctl logout 192.168.200.116:5080
```

- ä½¿ç”¨crictl

```bash
# æŸ¥çœ‹é•œåƒ
$ crictl images | grep openjdk
# æ‹‰å–é•œåƒ
$ crictl pull 192.168.200.116:5080/library/openjdk:8-jre
# åˆ é™¤é•œåƒ
$ crictl rmi 192.168.200.116:5080/library/openjdk:8-jre
```

##### 5.2.2.2 ä»…httpsæ¨¡å¼ã€å¤–ç½‘æ¨èã€‘

1. ç¼–è¾‘é…ç½®ï¼Œä»…httpsæ¨¡å¼

```bash
$ vim /usr/local/Harbor/harbor/harbor.yml
```

```bash
# Configuration file of Harbor

# The IP address or hostname to access admin UI and registry service.
# DO NOT use localhost or 127.0.0.1, because Harbor needs to be accessed by external clients.
hostname: reg.mydomain.com # [!code --] [!code focus:2]
hostname: 192.168.200.116 # [!code ++]

# http related config
http: # [!code --] [!code focus:1]
  # port for http, default is 80. If https enabled, this port will redirect to https port
  port: 80 # [!code --] [!code focus:1]

# https related config
https:
  # https port for harbor, default is 443
  port: 443 # [!code --] [!code focus:2]
  port: 5443 # [!code ++] [!code focus:1]
  # The path of cert and key files for nginx
  certificate: /your/certificate/path # [!code --] [!code focus:2]
  private_key: /your/private/key/path # [!code --] 
  # ä¿®æ”¹ï¼šæ³¨æ„ï¼Œè¿™é‡Œä¸èƒ½ä½¿ç”¨è½¯è¿æ¥ç›®å½• /usr/loca/harboræ›¿æ¢/usr/local/Harbor/harbor-2.13.1
  # å¦åˆ™ä¼šå‘ç”Ÿè¯ä¹¦æ‰¾ä¸åˆ°é”™è¯¯ï¼šFileNotFoundError: [Errno 2] No such file or directory: 
  certificate: /usr/local/Harbor/cert/emon.crt # [!code ++] [!code focus:2]
  private_key: /usr/local/Harbor/cert/emon.key # [!code ++]
  # enable strong ssl ciphers (default: false)
  # strong_ssl_ciphers: false
......
# The default data volume
data_volume: /data # [!code --] [!code focus:2]
data_volume: /usr/local/dockerv/harbor_home # [!code ++]
......
```

2. å®‰è£…

```bash
# åˆ‡æ¢ç›®å½•
$ cd /usr/local/Harbor/harbor/
# åŠ è½½ ARM æ¶æ„çš„ Harbor é•œåƒ
$ nerdctl load -i harbor.v2.13.1.tar.gz
# æ›¿æ¢dockerå‘½ä»¤åˆ°nerdctl
$ sed -i.bak s/docker/nerdctl/ prepare 
# ç”Ÿæˆdocker-compose.yaml
$ sh prepare
# è‹¥ä¸æ˜¯ç¬¬ä¸€æ¬¡å¯åŠ¨ï¼Œç§»é™¤å®¹å™¨å’Œå…³è”èµ„æº
# -v è¡¨ç¤ºåˆ é™¤Composeæ–‡ä»¶çš„volumeséƒ¨åˆ†ä¸­å£°æ˜çš„å‘½åå·å’Œé™„åŠ åˆ°å®¹å™¨çš„åŒ¿åå·ï¼Œæ¨èç”¨ -vï¼Œé™¤éæœ‰ç‰¹æ®ŠåŒ¿åå·æ•°æ®éœ€ä¿ç•™
$ nerdctl compose down -v
# åˆ›å»ºå¹¶å¯åŠ¨å®¹å™¨
$ nerdctl compose up -d
```

è®¿é—®ï¼šhttps://192.168.200.116:5443 

ç”¨æˆ·åå¯†ç ï¼š admin/Harbor12345

<span style="color:red;font-weight:bold;">ç™»å½•æ—¶å¦‚æœæç¤ºï¼šç”¨æˆ·åæˆ–è€…å¯†ç ä¸æ­£ç¡®ï¼Œåœ¨ç¡®è®¤ç”¨æˆ·åå¯†ç æ­£ç¡®çš„æƒ…å†µä¸‹ï¼Œè¯·æ¸…ç†æµè§ˆå™¨ç¼“å­˜ï¼ï¼ï¼</span>

3. containerdé…ç½®ï¼ˆæ‰€æœ‰èŠ‚ç‚¹ï¼‰

<span style="color:#9400D3;font-weight:bold;">è¿™ä¸ªé…ç½®å¯¹ctrã€nerdctlæ— æ•ˆï¼Œä½†å¯¹crictlç”Ÿæ•ˆ</span>ï¼ˆæ‰€æœ‰èŠ‚ç‚¹ï¼‰

- é…ç½®

```bash
$ vim /etc/containerd/config.toml
```

```toml
[plugins]
  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
    runtime_type = "io.containerd.runc.v2"
    [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
      SystemdCgroup = true
  [plugins."io.containerd.grpc.v1.cri"]
    sandbox_image = "registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.9"
    [plugins."io.containerd.grpc.v1.cri".cni]
      bin_dir = "/opt/cni/bin"
      conf_dir = "/etc/cni/net.d"
      max_conf_num = 1
      conf_template = ""
    [plugins."io.containerd.grpc.v1.cri".registry]
        [plugins."io.containerd.grpc.v1.cri".registry.mirrors] // [!code --] [!code focus:2]
      [plugins."io.containerd.grpc.v1.cri".registry.mirrors] // [!code ++]
        [plugins."io.containerd.grpc.v1.cri".registry.mirrors."docker.io"]
          endpoint = ["https://registry-1.docker.io"]
      [plugins."io.containerd.grpc.v1.cri".registry.configs] // [!code ++] [!code focus:3]
        [plugins."io.containerd.grpc.v1.cri".registry.configs."192.168.200.116:5443".tls] // [!code ++]
          insecure_skip_verify = true // [!code ++]
        # è‹¥æ˜¯ç§æœ‰åº“ï¼Œå¿…é¡»é…ç½®è¿™ä¸ª
        [plugins."io.containerd.grpc.v1.cri".registry.configs."192.168.200.116:5443".auth] // [!code ++] [!code focus:3]
          username = "admin" // [!code ++]
          password = "Harbor12345" # [!code ++]          
```

- é‡å¯

```bash
$ sudo systemctl restart containerd
```

4. æ¨é€é•œåƒ

- ä½¿ç”¨nerdctl

```bash
# ä¸‹è½½
$ https_proxy=http://192.168.200.1:7890 nerdctl pull openjdk:8-jre
# æ‰“æ ‡ç­¾
$ nerdctl tag openjdk:8-jre 192.168.200.116:5443/library/openjdk:8-jre
# ç™»å½•ï¼Œç™»å½•åä¿¡æ¯å­˜å‚¨åœ¨ç”¨æˆ·ç›®å½•ä¸‹çš„ .docker/config.json
# --insecure-registry å‘Šè¯‰ nerdctl å…è®¸ä½¿ç”¨ HTTP è¿æ¥ï¼ˆå¦åˆ™é»˜è®¤å¼ºåˆ¶ HTTPSï¼‰ã€‚
$ echo "Harbor12345" | nerdctl login --insecure-registry -u admin --password-stdin 192.168.200.116:5443
# ä¸Šä¼ é•œåƒ
$ nerdctl push --insecure-registry 192.168.200.116:5443/library/openjdk:8-jre
# é€€å‡ºç™»å½•
$ nerdctl logout 192.168.200.116:5443
```

- ä½¿ç”¨crictl

```bash
# æŸ¥çœ‹é•œåƒ
$ crictl images | grep openjdk
# æ‹‰å–é•œåƒ
$ crictl pull 192.168.200.116:5443/library/openjdk:8-jre
# åˆ é™¤é•œåƒ
$ crictl rmi 192.168.200.116:5443/library/openjdk:8-jre
```

##### 5.2.2.3 httpä¸httpsæ¨¡å¼éƒ½å¼€å¯ã€ä¸å¿…è¦ã€‘

1. ç¼–è¾‘é…ç½®ï¼Œå¼€å¯httpå’Œhttpsæ¨¡å¼

```bash
$ vim /usr/local/Harbor/harbor/harbor.yml
```

```bash
# Configuration file of Harbor

# The IP address or hostname to access admin UI and registry service.
# DO NOT use localhost or 127.0.0.1, because Harbor needs to be accessed by external clients.
hostname: reg.mydomain.com # [!code --] [!code focus:2]
hostname: 192.168.200.116 # [!code ++]

# http related config
http:
  # port for http, default is 80. If https enabled, this port will redirect to https port
  port: 80 # [!code --] [!code focus:2]
  port: 5080 # [!code ++] 

# https related config
https:
  # https port for harbor, default is 443
  port: 443 # [!code --] [!code focus:2]
  port: 5443 # [!code ++] [!code focus:1]
  # The path of cert and key files for nginx
  certificate: /your/certificate/path # [!code --] [!code focus:2]
  private_key: /your/private/key/path # [!code --] 
  # ä¿®æ”¹ï¼šæ³¨æ„ï¼Œè¿™é‡Œä¸èƒ½ä½¿ç”¨è½¯è¿æ¥ç›®å½• /usr/loca/harboræ›¿æ¢/usr/local/Harbor/harbor-2.13.1
  # å¦åˆ™ä¼šå‘ç”Ÿè¯ä¹¦æ‰¾ä¸åˆ°é”™è¯¯ï¼šFileNotFoundError: [Errno 2] No such file or directory: 
  certificate: /usr/local/Harbor/cert/emon.crt # [!code ++] [!code focus:2]
  private_key: /usr/local/Harbor/cert/emon.key # [!code ++]
  # enable strong ssl ciphers (default: false)
  # strong_ssl_ciphers: false
......
# The default data volume
data_volume: /data # [!code --] [!code focus:2]
data_volume: /usr/local/dockerv/harbor_home # [!code ++]
......
```

2. å®‰è£…

```bash
# åˆ‡æ¢ç›®å½•
$ cd /usr/local/Harbor/harbor/
# åŠ è½½ ARM æ¶æ„çš„ Harbor é•œåƒ
$ nerdctl load -i harbor.v2.13.1.tar.gz
# æ›¿æ¢dockerå‘½ä»¤åˆ°nerdctl
$ sed -i.bak s/docker/nerdctl/ prepare 
# ç”Ÿæˆdocker-compose.yaml
$ sh prepare
# è‹¥ä¸æ˜¯ç¬¬ä¸€æ¬¡å¯åŠ¨ï¼Œç§»é™¤å®¹å™¨å’Œå…³è”èµ„æº
# -v è¡¨ç¤ºåˆ é™¤Composeæ–‡ä»¶çš„volumeséƒ¨åˆ†ä¸­å£°æ˜çš„å‘½åå·å’Œé™„åŠ åˆ°å®¹å™¨çš„åŒ¿åå·ï¼Œæ¨èç”¨ -vï¼Œé™¤éæœ‰ç‰¹æ®ŠåŒ¿åå·æ•°æ®éœ€ä¿ç•™
$ nerdctl compose down -v
# åˆ›å»ºå¹¶å¯åŠ¨å®¹å™¨
$ nerdctl compose up -d
```

è®¿é—®ï¼šhttp://192.168.200.116:5080 ï¼ˆä¼šè¢«è·³è½¬åˆ°http://192.168.200.116:5443ï¼‰<span style="color:red;font-weight:bold;">æ³¨æ„ï¼šæ— æ³•ç›´æ¥è®¿é—®5443ç«¯å£</span>

ç”¨æˆ·åå¯†ç ï¼š admin/Harbor12345

<span style="color:red;font-weight:bold;">ç™»å½•æ—¶å¦‚æœæç¤ºï¼šç”¨æˆ·åæˆ–è€…å¯†ç ä¸æ­£ç¡®ï¼Œåœ¨ç¡®è®¤ç”¨æˆ·åå¯†ç æ­£ç¡®çš„æƒ…å†µä¸‹ï¼Œè¯·æ¸…ç†æµè§ˆå™¨ç¼“å­˜ï¼ï¼ï¼</span>

3. containerdé…ç½®ï¼ˆæ‰€æœ‰èŠ‚ç‚¹ï¼‰

<span style="color:#9400D3;font-weight:bold;">è¿™ä¸ªé…ç½®å¯¹ctrã€nerdctlæ— æ•ˆï¼Œä½†å¯¹crictlç”Ÿæ•ˆ</span>ï¼ˆæ‰€æœ‰èŠ‚ç‚¹ï¼‰

- é…ç½®

```bash
$ vim /etc/containerd/config.toml
```

```toml
[plugins]
  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
    runtime_type = "io.containerd.runc.v2"
    [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
      SystemdCgroup = true
  [plugins."io.containerd.grpc.v1.cri"]
    sandbox_image = "registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.9"
    [plugins."io.containerd.grpc.v1.cri".cni]
      bin_dir = "/opt/cni/bin"
      conf_dir = "/etc/cni/net.d"
      max_conf_num = 1
      conf_template = ""
    [plugins."io.containerd.grpc.v1.cri".registry]
        [plugins."io.containerd.grpc.v1.cri".registry.mirrors] // [!code --] [!code focus:2]
      [plugins."io.containerd.grpc.v1.cri".registry.mirrors] // [!code ++]
        [plugins."io.containerd.grpc.v1.cri".registry.mirrors."docker.io"]
          endpoint = ["https://registry-1.docker.io"]
        # å¢åŠ è¯¥é…ç½®ï¼Œcrictlè®¿é—®5080ä¼šè¢«è½¬å‘åˆ°5443
        [plugins."io.containerd.grpc.v1.cri".registry.mirrors."192.168.200.116:5080"] // [!code ++] [!code focus:2]
          endpoint = ["https://192.168.200.116:5443"] // [!code ++]
      [plugins."io.containerd.grpc.v1.cri".registry.configs] // [!code ++] [!code focus:3]
        [plugins."io.containerd.grpc.v1.cri".registry.configs."192.168.200.116:5443".tls] // [!code ++]
          insecure_skip_verify = true // [!code ++]
        # è‹¥æ˜¯ç§æœ‰åº“ï¼Œå¿…é¡»é…ç½®è¿™ä¸ª
        [plugins."io.containerd.grpc.v1.cri".registry.configs."192.168.200.116:5443".auth] // [!code ++] [!code focus:3]
          username = "admin" // [!code ++]
          password = "Harbor12345" # [!code ++]          
```

- é‡å¯

```bash
$ sudo systemctl restart containerd
```

4. æ¨é€é•œåƒ

- ä½¿ç”¨nerdctl

<span style="color:#9400D3;font-weight:bold;">httpå’Œhttpséƒ½å¼€å¯ï¼Œnerdctlåªè®¤5443ç«¯å£</span>

```bash
# ä¸‹è½½
$ https_proxy=http://192.168.200.1:7890 nerdctl pull openjdk:8-jre
# æ‰“æ ‡ç­¾
$ nerdctl tag openjdk:8-jre 192.168.200.116:5443/library/openjdk:8-jre
# ç™»å½•ï¼Œç™»å½•åä¿¡æ¯å­˜å‚¨åœ¨ç”¨æˆ·ç›®å½•ä¸‹çš„ .docker/config.json
# --insecure-registry å‘Šè¯‰ nerdctl å…è®¸ä½¿ç”¨ HTTP è¿æ¥ï¼ˆå¦åˆ™é»˜è®¤å¼ºåˆ¶ HTTPSï¼‰ã€‚
$ echo "Harbor12345" | nerdctl login --insecure-registry -u admin --password-stdin 192.168.200.116:5443
# ä¸Šä¼ é•œåƒ
$ nerdctl push --insecure-registry 192.168.200.116:5443/library/openjdk:8-jre
# é€€å‡ºç™»å½•
$ nerdctl logout 192.168.200.116:5443
```

- ä½¿ç”¨crictl

<span style="color:#9400D3;font-weight:bold;">httpå’Œhttpséƒ½å¼€å¯,crictlåœ¨containerdè½¬å‘5080åˆ°5443æƒ…å†µä¸‹ï¼Œå¯ä»¥è®¤å¾—5080å’Œ5443ä¸¤ä¸ªç«¯å£</span>

```bash
# æŸ¥çœ‹é•œåƒ
$ crictl images | grep openjdk
# æ‹‰å–é•œåƒ
$ crictl pull 192.168.200.116:5443/library/openjdk:8-jre
$ crictl pull 192.168.200.116:5080/library/openjdk:8-jre
# åˆ é™¤é•œåƒ
$ crictl rmi 192.168.200.116:5443/library/openjdk:8-jre
$ crictl rmi 192.168.200.116:5080/library/openjdk:8-jre
```

### 5.3 åœ¨K8Sä¸Šå®‰è£…

#### 5.3.1 å®‰è£…nerdctl

[å®‰è£…nerdctl](/devops/new/Kubernetes/05-%E7%AC%AC5%E7%AB%A0%20Kubernetes%E6%89%A9%E5%B1%95%E5%AE%89%E8%A3%85.html#_5-2-1-%E5%AE%89%E8%A3%85nerdctl-%E9%9A%90%E5%90%ABnerdctl-compose)

#### 5.3.2 å®‰è£…Harboré•œåƒç§æœï¼ˆhelm+arm64ç‰ˆï¼‰

1. è§£å†³é•œåƒä¸æ”¯æŒarm64æ¶æ„çš„æƒ…å†µ

<span style="color:#9400D3;font-weight:bold;">åœ¨emonä¸»æœºrootç”¨æˆ·å®‰è£…</span>

```bash
# ä¸‹è½½ ARM64 ç‰ˆ nerdctlï¼ˆå…¼å®¹ containerd 1.7.13ï¼‰
$ wget https://github.com/containerd/nerdctl/releases/download/v2.1.3/nerdctl-2.1.3-linux-arm64.tar.gz
$ tar Cxzvf /usr/local/bin nerdctl-2.1.3-linux-arm64.tar.gz
# ä¸‹è½½ ARM64 ç‰ˆ harboré•œåƒ
$ wget https://github.com/IabSDocker/harbor/releases/download/v2.13.1/harbor-offline-installer-v2.13.1_arm64.tgz
# æŸ¥çœ‹åŒ…å†…æ–‡ä»¶
$ tar -ztvf harbor-offline-installer-v2.13.1_arm64.tgz
# åŠ è½½é•œåƒåˆ° k8s.io å‘½åç©ºé—´
$ tar -xOzf harbor-offline-installer-v2.13.1_arm64.tgz harbor/harbor.v2.13.1.tar.gz | nerdctl -n k8s.io load
```

> å…¶ä»–èŠ‚ç‚¹ï¼Œå¦‚ä¸Šå¤„ç†ï¼š
>
> ```bash
> # æ‹·è´åˆ°é›†ç¾¤ä¸­å…¶ä»–èŠ‚ç‚¹
> $ kubectl get nodes -o name | awk -F'/' '{print $2}' | grep -v '^emon$' | xargs -I {} scp harbor-offline-installer-v2.13.1_arm64.tgz nerdctl-2.1.3-linux-arm64.tar.gz root@{}:/root
> ```

2. å®‰è£…

æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œä½¿ç”¨ Helm 3 å®‰è£… Harborã€‚

- é€šè¿‡hemlå®‰è£…

```bash
$ helm repo add harbor https://helm.goharbor.io
$ helm install harbor harbor/harbor -n harbor-system --create-namespace --set expose.type=nodePort,externalURL=http://192.168.200.116:30002,expose.tls.enabled=false
```

- éªŒè¯ï¼Œç¡®ä¿æ‰€æœ‰ pod éƒ½running

```bash
$ kubectl get po -n harbor-system
```

è®¿é—®ï¼š http://192.168.200.116:30002

ç”¨æˆ·åå¯†ç ï¼šadmin/Harbor12345

<span style="color:red;font-weight:bold;">ç™»å½•æ—¶å¦‚æœæç¤ºï¼šç”¨æˆ·åæˆ–è€…å¯†ç ä¸æ­£ç¡®ï¼Œåœ¨ç¡®è®¤ç”¨æˆ·åå¯†ç æ­£ç¡®çš„æƒ…å†µä¸‹ï¼Œè¯·æ¸…ç†æµè§ˆå™¨ç¼“å­˜ï¼ï¼ï¼</span>

- å¸è½½

```bash
$ helm uninstall harbor -n harbor-system
# åˆ é™¤K8Så‘½åç©ºé—´ï¼ˆé—´æ¥åˆ é™¤é…ç½®ç­‰ä»è¢«ä¿ç•™çš„èµ„æºï¼‰
$ kubectl delete ns harbor-system
```

3. containerdé…ç½®ï¼ˆæ‰€æœ‰èŠ‚ç‚¹ï¼‰

<span style="color:#9400D3;font-weight:bold;">è¿™ä¸ªé…ç½®å¯¹ctrã€nerdctlæ— æ•ˆï¼Œä½†å¯¹crictlç”Ÿæ•ˆ</span>ï¼ˆæ‰€æœ‰èŠ‚ç‚¹ï¼‰

- é…ç½®

```bash
$ vim /etc/containerd/config.toml
```

```toml
[plugins]
  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
    runtime_type = "io.containerd.runc.v2"
    [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
      SystemdCgroup = true
  [plugins."io.containerd.grpc.v1.cri"]
    sandbox_image = "registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.9"
    [plugins."io.containerd.grpc.v1.cri".cni]
      bin_dir = "/opt/cni/bin"
      conf_dir = "/etc/cni/net.d"
      max_conf_num = 1
      conf_template = ""
    [plugins."io.containerd.grpc.v1.cri".registry]
        [plugins."io.containerd.grpc.v1.cri".registry.mirrors] // [!code --] [!code focus:2]
      [plugins."io.containerd.grpc.v1.cri".registry.mirrors] // [!code ++]
        [plugins."io.containerd.grpc.v1.cri".registry.mirrors."docker.io"]
          endpoint = ["https://registry-1.docker.io"]
        [plugins."io.containerd.grpc.v1.cri".registry.mirrors."192.168.200.116:30002"] // [!code ++] [!code focus:2]
          endpoint = ["http://192.168.200.116:30002"] // [!code ++]
```

- é‡å¯

```bash
$ sudo systemctl restart containerd
```

4. æ¨é€é•œåƒ

- ä½¿ç”¨nerdctl

```bash
# ä¸‹è½½
$ https_proxy=http://192.168.200.1:7890 nerdctl pull openjdk:8-jre
# æ‰“æ ‡ç­¾
$ nerdctl tag openjdk:8-jre 192.168.200.116:30002/library/openjdk:8-jre
# ç™»å½•ï¼Œç™»å½•åä¿¡æ¯å­˜å‚¨åœ¨ç”¨æˆ·ç›®å½•ä¸‹çš„ .docker/config.json
# --insecure-registry å‘Šè¯‰ nerdctl å…è®¸ä½¿ç”¨ HTTP è¿æ¥ï¼ˆå¦åˆ™é»˜è®¤å¼ºåˆ¶ HTTPSï¼‰ã€‚
$ echo "Harbor12345" | nerdctl login --insecure-registry -u admin --password-stdin 192.168.200.116:30002
# ä¸Šä¼ é•œåƒ
$ nerdctl push --insecure-registry 192.168.200.116:30002/library/openjdk:8-jre
# é€€å‡ºç™»å½•
$ nerdctl logout 192.168.200.116:30002
```

- ä½¿ç”¨crictl

```bash
# æŸ¥çœ‹é•œåƒ
$ crictl images | grep openjdk
# æ‹‰å–é•œåƒ
$ crictl pull 192.168.200.116:30002/library/openjdk:8-jre
# åˆ é™¤é•œåƒ
$ crictl rmi 192.168.200.116:30002/library/openjdk:8-jre
```



## 9 æ–°ä»¤ç‰Œä¸è¯ä¹¦

### 9.1 kubeadmå¦‚ä½•åŠ å…¥èŠ‚ç‚¹ï¼ˆåœ¨masterèŠ‚ç‚¹æ‰§è¡Œï¼‰

- é‡æ–°ç”Ÿæˆæ–°çš„token

```bash
$ kubeadm token create --print-join-command
```

```bash
kubeadm join emon:6443 --token yslydb.mkmtnbjpfkuaa85n --discovery-token-ca-cert-hash sha256:7268baf811b3f1f2ca1e657fe90db99b8d3ed3f9efb8be03811b809d8efa5c5e 
```

> - æŸ¥çœ‹æ‰€æœ‰tokenåˆ—è¡¨
>
> ```bash
> $ kubeadm token list
> ```
>
> - è·å–caè¯ä¹¦sha256ç¼–ç hashå€¼
>
> ```bash
> $ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'
> ```



- ç”Ÿæˆä¸€ä¸ªæ°¸ä¸è¿‡æœŸçš„token

```bash
$ token=$(kubeadm token generate)
$ kubeadm token create $token --print-join-command --ttl=0
```

è¯´æ˜ï¼š`--ttl=0`,è¡¨ç¤ºæ°¸ä¸å¤±æ•ˆ



- åˆ é™¤token

```bash
$ kubeadm delete [token-value] ...
```

> ç¤ºä¾‹ï¼š`kubeadm token delete yslydb.mkmtnbjpfkuaa85n nbdvuh.whaq4d2xm5vr6cih`

### 9.2 æŸ¥çœ‹kubeadmæ­å»ºé›†ç¾¤çš„è¯ä¹¦è¿‡æœŸæ—¶é—´ï¼ˆæ‰€æœ‰èŠ‚ç‚¹çš†å¯ï¼‰

```bash
$ cd /etc/kubernetes/pki/ && for i in $(ls *.crt); do echo "===== $i ====="; openssl x509 -in $i -text -noout | grep -A 3 'Validity' ; done
```

- ä½¿ç”¨ **kubeadm** æŸ¥çœ‹

```bash
$ kubeadm certs check-expiration
```

- ä½¿ç”¨ **kk** æŸ¥çœ‹

```bash
$ ./kk certs check-expiration -f ksp-k8s-v1306.yaml
```

